{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "437ea33d",
   "metadata": {},
   "source": [
    "# Text Pattern Analysis Tool for Documents\n",
    "## A Computational Approach to Document Analysis\n",
    "\n",
    "### Overview\n",
    "This tool provides a systematic approach to analyze patterns and terms across historical documents (PDF and DOCX formats), enabling researchers to track the occurrence and context of specific concepts over time.\n",
    "\n",
    "### Key Features\n",
    "1. **Document Processing**\n",
    "   - Handles both PDF and DOCX formats\n",
    "   - Extracts text while maintaining page references\n",
    "   - Processes documents with year-based naming convention (e.g., \"1946-document-name.pdf\")\n",
    "\n",
    "2. **Pattern Search**\n",
    "   - Customizable search patterns using regular expressions\n",
    "   - Case-insensitive matching\n",
    "   - Root word and variation detection\n",
    "   - Contextual excerpt extraction\n",
    "\n",
    "3. **Analysis & Visualization**\n",
    "   - Chronological pattern distribution\n",
    "   - Pattern frequency analysis\n",
    "   - Page-specific references\n",
    "   - Context preservation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d54add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 - Installation and Imports (Detailed):\n",
    "# Install required packages for document processing and data analysis\n",
    "!pip install PyPDF2 python-docx rtfparse matplotlib pandas\n",
    "!pip install pyth\n",
    "!pip install PyMuPDF\n",
    "import os\n",
    "import re\n",
    "import fitz  # PyMuPDF\n",
    "from docx import Document\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import html\n",
    "from IPython.display import display, HTML\n",
    "# Verify imports\n",
    "for module in [os, re, fitz, Document, plt, pd, defaultdict]:\n",
    "    print(f\"Successfully imported {module.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7763a304",
   "metadata": {},
   "source": [
    "# Search Pattern Configuration (Cell 2A)\n",
    "\n",
    "## Overview\n",
    "This cell allows you to define search patterns for text analysis in PDF and DOCX documents. You can search for single words, word variations, or multiple terms simultaneously.\n",
    "\n",
    "## Pattern Structure Explained\n",
    "\n",
    "### Basic Components\n",
    "- `r'...'` : Raw string indicator\n",
    "- `(?i)` : Case insensitive flag\n",
    "- `\\b` : Word boundary\n",
    "- `\\w*` : Wildcard for word characters\n",
    "- `\\b` : Word boundary\n",
    "\n",
    "### Single Pattern Example\n",
    "```python\n",
    "patterns = [r'(?i)\\bmysti\\w*\\b']  # Searches for: mystic, mystical, mysticism, etc.\n",
    "\n",
    "patterns = [r'(?i)\\bkirche\\b']  # Matches exactly \"kirche\" (case insensitive)\n",
    "\n",
    "patterns = [r'(?i)\\bkirch\\w*\\b']  # Matches: kirche, kirchlich, kirchlichen, etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194ef93b",
   "metadata": {},
   "source": [
    "# Bible Verse Pattern Matching Guide\n",
    "\n",
    "## Overview\n",
    "The regex pattern for Bible verses needs to be customized based on the specific abbreviations and citation styles found in your ocr documents. Different historical periods, denominations, and languages may use varying citation formats.\n",
    "\n",
    "## Basic Pattern Template\n",
    "```python\n",
    "# Customizable Bible reference pattern\n",
    "bible_pattern = r'(?i)(?:(?:SINGLE_BOOKS)\\.?\\s|[1-5]\\s*(?:NUMBERED_BOOKS)\\.)\\s*\\d+(?:\\s*,\\s*\\d+(?:\\s*[-—]\\s*\\d+)?)?'\n",
    "\n",
    "# Separate book lists for easy modification\n",
    "single_books = r'(?:Ps|Joh|Matt|Luk|Mark|Röm|Kor|Tim|Petr|Thess|Offb|Hes|Jes|Jer|Spr|Pred|Hld|Kol|Phil|Gal|Eph)'\n",
    "numbered_books = r'(?:Mos|Joh|Kor|Tim|Petr|Thess)'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44eb443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2 A - Configuration Setup (Detailed):\n",
    "# Define your search patterns here\n",
    "# Format: [r'(?i)\\bword\\w*\\b']\n",
    "# (?i) - case insensitive\n",
    "# \\b - word boundary\n",
    "# \\w* - followed by any word characters\n",
    "\n",
    "# Example: [r'(?i)\\bmysti\\w*\\b'] will match: mystical, mysticism, etc.\n",
    "\n",
    "# regex pattern match for Bible verses should be modified depending on abbrevations and individual cases.\n",
    "# Exmaple for Basic pattern for Bible verses: [r'(?i)(?:(?:Ps|Joh|Matt|Luk|Mark|Röm|Kor|Tim|Petr|Thess|Offb|Hes|Jes|Jer|Spr|Pred|Hld|Kol|Phil|Gal|Eph)\\.|[1-5]\\s*(?:Mos|Joh|Kor|Tim|Petr|Thess)\\.)\\s*\\d+(?:\\s*,\\s*\\d+(?:\\s*[-—]\\s*\\d+)?)?']\n",
    "\n",
    "\n",
    "# single search terms\n",
    "\n",
    "# patterns = [r'(?i)\\bmysti\\w*\\b']  # <-- Modify this line to change search terms\n",
    "\n",
    "# multilple search terms\n",
    "patterns = [\n",
    "    r'(?i)\\bmysti\\w*\\b',    # First search term\n",
    "    r'(?i)\\bleid\\w*\\b',     # Second search term\n",
    "    r'(?i)\\brechtfertw*\\b',  # Third search term\n",
    "    #for Bible verses uncomment the line\n",
    "    #r'(?i)(?:(?:Ps|Joh|Matt|Luk|Mark|Apostelgesch|Röm|Rö|Kor|Tim|Petr|Thess|Offb|Hes|Jes|Jer|Spr|Pred|Hld|Kol|Phil|Gal|Eph)\\.?|[1-5]\\s*(?:Mos|Joh|Kor|Tim|Petr|Thess)\\.?)\\s*?\\d+(?:\\s*,\\s*\\d+(?:\\s*[-—]\\s*\\d+)?)?',\n",
    "]\n",
    "\n",
    "\n",
    "# Verify pattern setup\n",
    "print(\"Current search patterns:\")\n",
    "for i, pattern in enumerate(patterns, 1):\n",
    "    print(f\"Pattern {i}: {pattern}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3701d8b-7c6e-430b-9af8-aacd61c78e34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 2 B - Configuration Setup (Detailed):\n",
    "# Define the working directory where files are located\n",
    "directory = './data'\n",
    "print(f\"Working directory: {directory}\")\n",
    "\n",
    "# Initialize counting dictionaries\n",
    "pattern_counts_by_year_title_page = {pattern: {} for pattern in patterns}\n",
    "total_pattern_counts = {pattern: 0 for pattern in patterns}\n",
    "\n",
    "# Define page offsets for specific documents\n",
    "# Used to skip front matter, covers, etc.\n",
    "file_start_pages = {\n",
    "    '1946-jahrbuch-des-lutherbundes_searchable.pdf': 5,  # Skip first 5 pages\n",
    "    '1947-jahrbuch-des-lutherbundes_searchable.pdf': 4,  # Skip first 4 pages\n",
    "    '1948-jahrbuch-des-lutherbundes_searchable.pdf': 5   # Skip first 5 pages\n",
    "}\n",
    "\n",
    "# Verify setup\n",
    "print(\"\\nInitialization complete:\")\n",
    "print(f\"Number of patterns: {len(patterns)}\")\n",
    "print(f\"Number of files with custom page offsets: {len(file_start_pages)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0173f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3 - PDF Processing Functions (Detailed):\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extract text and page numbers from PDF files.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path (str): Path to PDF file\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (pdf_text, page_numbers)\n",
    "            - pdf_text: Dict mapping page numbers to text content\n",
    "            - page_numbers: Dict mapping physical to logical page numbers\n",
    "    \"\"\"\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    pdf_text = {}\n",
    "    page_numbers = {}\n",
    "    \n",
    "    filename = os.path.basename(pdf_path)\n",
    "    skip_pages = file_start_pages.get(filename, 0)\n",
    "    \n",
    "    for page_num in range(pdf_document.page_count):\n",
    "        page = pdf_document.load_page(page_num)\n",
    "        text = page.get_text().strip()\n",
    "        \n",
    "        if text and page_num >= skip_pages:\n",
    "            adjusted_page_num = page_num - skip_pages + 1\n",
    "            pdf_text[adjusted_page_num] = text\n",
    "            page_numbers[adjusted_page_num] = adjusted_page_num\n",
    "    \n",
    "    pdf_document.close()\n",
    "    return pdf_text, page_numbers\n",
    "\n",
    "def print_pdf_contents(directory, max_initial_items=5):\n",
    "    \"\"\"\n",
    "    Display contents of PDFs in a scrollable element with expandable sections.\n",
    "    \n",
    "    Args:\n",
    "        directory (str): Path to directory containing PDFs\n",
    "        max_initial_items (int): Number of items to show initially\n",
    "    \"\"\"\n",
    "    # CSS for styling\n",
    "    css = \"\"\"\n",
    "    <style>\n",
    "        .pdf-container {\n",
    "            max-height: 500px;\n",
    "            overflow-y: auto;\n",
    "            border: 1px solid #ccc;\n",
    "            padding: 10px;\n",
    "            margin: 10px 0;\n",
    "            font-family: monospace;\n",
    "        }\n",
    "        .file-section {\n",
    "            margin-bottom: 20px;\n",
    "            border-bottom: 1px solid #eee;\n",
    "        }\n",
    "        .file-header {\n",
    "            font-weight: bold;\n",
    "            color: #2c3e50;\n",
    "            margin: 10px 0;\n",
    "        }\n",
    "        .page-preview {\n",
    "            margin-left: 20px;\n",
    "            color: #34495e;\n",
    "        }\n",
    "        .show-more {\n",
    "            color: blue;\n",
    "            cursor: pointer;\n",
    "            text-decoration: underline;\n",
    "        }\n",
    "        .hidden {\n",
    "            display: none;\n",
    "        }\n",
    "    </style>\n",
    "    \"\"\"\n",
    "    \n",
    "    # JavaScript for show more functionality\n",
    "    javascript = \"\"\"\n",
    "    <script>\n",
    "        function toggleContent(fileId) {\n",
    "            var content = document.getElementById(fileId);\n",
    "            var button = document.getElementById('btn-' + fileId);\n",
    "            if (content.classList.contains('hidden')) {\n",
    "                content.classList.remove('hidden');\n",
    "                button.innerHTML = 'Show less';\n",
    "            } else {\n",
    "                content.classList.add('hidden');\n",
    "                button.innerHTML = 'Show more';\n",
    "            }\n",
    "        }\n",
    "    </script>\n",
    "    \"\"\"\n",
    "    \n",
    "    html_content = [css, javascript, '<div class=\"pdf-container\">']\n",
    "    \n",
    "    for idx, filename in enumerate(os.listdir(directory)):\n",
    "        if filename.endswith('.pdf'):\n",
    "            try:\n",
    "                pdf_path = os.path.join(directory, filename)\n",
    "                file_id = f'file-{idx}'\n",
    "                \n",
    "                html_content.append(f'<div class=\"file-section\">')\n",
    "                html_content.append(f'<div class=\"file-header\">Processing: {html.escape(filename)}</div>')\n",
    "                html_content.append(f'Starting page offset: {file_start_pages.get(filename, 0)}')\n",
    "                html_content.append('<hr>')\n",
    "                \n",
    "                pdf_text, page_numbers = extract_text_from_pdf(pdf_path)\n",
    "                \n",
    "                # Show initial items\n",
    "                for i, page_num in enumerate(sorted(pdf_text.keys())[:max_initial_items]):\n",
    "                    text = pdf_text[page_num]\n",
    "                    html_content.append(\n",
    "                        f'<div class=\"page-preview\">Page {page_numbers[page_num]}: '\n",
    "                        f'{html.escape(text[:50])}...</div>'\n",
    "                    )\n",
    "                \n",
    "                # Add remaining items in hidden div if there are more pages\n",
    "                if len(pdf_text) > max_initial_items:\n",
    "                    html_content.append(\n",
    "                        f'<div id=\"{file_id}\" class=\"hidden\">'\n",
    "                    )\n",
    "                    for page_num in sorted(pdf_text.keys())[max_initial_items:]:\n",
    "                        text = pdf_text[page_num]\n",
    "                        html_content.append(\n",
    "                            f'<div class=\"page-preview\">Page {page_numbers[page_num]}: '\n",
    "                            f'{html.escape(text[:50])}...</div>'\n",
    "                        )\n",
    "                    html_content.append('</div>')\n",
    "                    html_content.append(\n",
    "                        f'<p><a class=\"show-more\" id=\"btn-{file_id}\" '\n",
    "                        f'onclick=\"toggleContent(\\'{file_id}\\')\">Show more</a></p>'\n",
    "                    )\n",
    "                \n",
    "            except Exception as e:\n",
    "                html_content.append(f'<div class=\"error\">Error processing {html.escape(filename)}: {str(e)}</div>')\n",
    "    \n",
    "    html_content.append('</div>')\n",
    "    \n",
    "    # Display the HTML\n",
    "    display(HTML(''.join(html_content)))\n",
    "\n",
    "# Execute PDF processing with scrollable output\n",
    "print_pdf_contents(directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bff1208-f90e-4512-9dca-666168154d9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 4 - Advanced Page Number Detection (Detailed):\n",
    "def extract_potential_page_numbers(page, filename):\n",
    "    \"\"\"\n",
    "    Extract page numbers with customized settings for each file.\n",
    "    \n",
    "    Args:\n",
    "        page (fitz.Page): PDF page object\n",
    "        filename (str): Name of the PDF file\n",
    "    \n",
    "    Returns:\n",
    "        list: List of detected page numbers\n",
    "    \"\"\"\n",
    "    # Default settings for page number detection\n",
    "\n",
    "    \"\"\"\n",
    "    Dimension Reference:\n",
    "    - Width (100 points) ≈ 3.5 cm\n",
    "    - Height (50 points) ≈ 1.8 cm\n",
    "\n",
    "    These dimensions create search boxes in each corner that are:\n",
    "    - 3.5 cm wide\n",
    "    - 1.8 cm high\n",
    "\n",
    "    You can adjust these values based on your needs:\n",
    "    - For larger search areas: increase the values\n",
    "    - For smaller search areas: decrease the values\n",
    "\n",
    "    Example adjustments:\n",
    "    - For 5cm width: use 142 points (5 cm × 72/2.54)\n",
    "    - For 2cm height: use 57 points (2 cm × 72/2.54)\n",
    "    \"\"\"\n",
    "    default_settings = {\n",
    "        'HIGHT': 50,  # Height of search area (approximately 1.8 cm)\n",
    "        'WIDTH': 100,  # Width of search area (approximately 3.5 cm)\n",
    "        'patterns': [r'\\b\\d{1,3}\\b']  # Match 1-3 digit numbers\n",
    "    }\n",
    "    \n",
    "    # Custom settings for specific files\n",
    "    file_settings = {\n",
    "        '1948-jahrbuch-des-lutherbundes_searchable.pdf': {\n",
    "            'HIGHT': 50,\n",
    "            'WIDTH': 100,\n",
    "            'patterns': [r'\\b\\d{1,3}\\b'],\n",
    "            'regions': ['botom_right', 'top_left', 'bottom_right'] # define detecting area of pages 'bottom\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Get appropriate settings for current file\n",
    "    settings = file_settings.get(filename, default_settings)\n",
    "    \n",
    "    # Define search regions on page\n",
    "    all_regions = {\n",
    "        'top_left': (0, 0, settings['WIDTH'], settings['HIGHT']),\n",
    "        'top_center': (page.rect.width/2 - settings['WIDTH']/2, 0, \n",
    "                      page.rect.width/2 + settings['WIDTH']/2, settings['HIGHT']),\n",
    "        'top_right': (page.rect.width - settings['WIDTH'], 0, \n",
    "                     page.rect.width, settings['HIGHT']),\n",
    "        # Bottom regions\n",
    "        'bottom_left': (0, page.rect.height - settings['HIGHT'],\n",
    "                       settings['WIDTH'], page.rect.height),\n",
    "        'bottom_center': (page.rect.width/2 - settings['WIDTH']/2, \n",
    "                         page.rect.height - settings['HIGHT'],\n",
    "                         page.rect.width/2 + settings['WIDTH']/2, \n",
    "                         page.rect.height),\n",
    "        'bottom_right': (page.rect.width - settings['WIDTH'], \n",
    "                        page.rect.height - settings['HIGHT'],\n",
    "                        page.rect.width, \n",
    "                        page.rect.height),\n",
    "    }\n",
    "\n",
    "    # Extract and validate numbers\n",
    "    numbers = []\n",
    "    for region_name, coords in all_regions.items():\n",
    "        text_block = page.get_text(\"text\", clip=coords)\n",
    "        for pattern in settings['patterns']:\n",
    "            found = re.findall(pattern, text_block)\n",
    "            for match in found:\n",
    "                try:\n",
    "                    num = int(match)\n",
    "                    if 0 < num < 1000:  # Reasonable page number range\n",
    "                        numbers.append(num)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "    \n",
    "    return list(set(numbers))  # Return unique numbers only\n",
    "\n",
    "def validate_page_numbers(page_numbers, total_pages):\n",
    "    \"\"\"\n",
    "    Validate and correct page numbers.\n",
    "    \n",
    "    Args:\n",
    "        page_numbers (dict): Detected page numbers\n",
    "        total_pages (int): Total pages in document\n",
    "    \n",
    "    Returns:\n",
    "        dict: Corrected page numbers\n",
    "    \"\"\"\n",
    "    corrected_numbers = {}\n",
    "    \n",
    "    for page, numbers in sorted(page_numbers.items()):\n",
    "        # Default to physical page number if no numbers found\n",
    "        if not numbers:\n",
    "            corrected_numbers[page] = page\n",
    "            continue\n",
    "            \n",
    "        # Validate detected numbers\n",
    "        for num in numbers:\n",
    "            if isinstance(num, str) and num.isdigit():\n",
    "                num_int = int(num)\n",
    "                if 0 < num_int <= total_pages + 50:\n",
    "                    corrected_numbers[page] = num_int\n",
    "                    break\n",
    "        \n",
    "        # Use first available number if no valid number found\n",
    "        if page not in corrected_numbers:\n",
    "            corrected_numbers[page] = numbers[0]\n",
    "    \n",
    "    return corrected_numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa395b0-5885-491c-b0b7-8a157993c144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5 - Page Detection Implementation (Detailed):\n",
    "\n",
    "def print_detected_pages(pdf_directory, max_initial_items=3):\n",
    "    \"\"\"\n",
    "    Display detected page numbers in a scrollable element with expandable sections.\n",
    "    \n",
    "    Args:\n",
    "        pdf_directory (str): Path to directory containing PDFs\n",
    "        max_initial_items (int): Number of items to show initially per file\n",
    "    \"\"\"\n",
    "    css = \"\"\"\n",
    "    <style>\n",
    "        .detection-container {\n",
    "            max-height: 500px;\n",
    "            overflow-y: auto;\n",
    "            border: 1px solid #ccc;\n",
    "            padding: 15px;\n",
    "            margin: 10px 0;\n",
    "            font-family: monospace;\n",
    "            background-color: #f8f9fa;\n",
    "        }\n",
    "        .file-section {\n",
    "            margin-bottom: 20px;\n",
    "            border-bottom: 1px solid #eee;\n",
    "        }\n",
    "        .file-header {\n",
    "            color: #2c3e50;\n",
    "            font-weight: bold;\n",
    "            margin: 10px 0;\n",
    "            padding: 5px;\n",
    "            background-color: #e9ecef;\n",
    "            border-radius: 3px;\n",
    "        }\n",
    "        .page-info {\n",
    "            margin-left: 20px;\n",
    "            color: #34495e;\n",
    "            padding: 2px 0;\n",
    "        }\n",
    "        .error-message {\n",
    "            color: #dc3545;\n",
    "            margin-left: 20px;\n",
    "        }\n",
    "        .summary {\n",
    "            margin-top: 15px;\n",
    "            padding: 10px;\n",
    "            background-color: #e9ecef;\n",
    "            border-radius: 3px;\n",
    "        }\n",
    "        .show-more {\n",
    "            color: #007bff;\n",
    "            cursor: pointer;\n",
    "            text-decoration: underline;\n",
    "            margin-left: 20px;\n",
    "            font-size: 0.9em;\n",
    "        }\n",
    "        .hidden {\n",
    "            display: none;\n",
    "        }\n",
    "    </style>\n",
    "    \"\"\"\n",
    "    \n",
    "    javascript = \"\"\"\n",
    "    <script>\n",
    "        function toggleContent(fileId) {\n",
    "            var content = document.getElementById(fileId);\n",
    "            var button = document.getElementById('btn-' + fileId);\n",
    "            if (content.classList.contains('hidden')) {\n",
    "                content.classList.remove('hidden');\n",
    "                button.innerHTML = 'Show less';\n",
    "            } else {\n",
    "                content.classList.add('hidden');\n",
    "                button.innerHTML = 'Show more';\n",
    "            }\n",
    "        }\n",
    "    </script>\n",
    "    \"\"\"\n",
    "    \n",
    "    html_content = [css, javascript, '<div class=\"detection-container\">']\n",
    "    html_content.append('<h3>Starting page detection process...</h3>')\n",
    "    \n",
    "    processed_files = 0\n",
    "    total_pages_processed = 0\n",
    "    \n",
    "    for file_idx, filename in enumerate(os.listdir(directory)):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            try:\n",
    "                doc = fitz.open(os.path.join(pdf_directory, filename))\n",
    "                file_id = f'file-{file_idx}'\n",
    "                \n",
    "                # Add file section\n",
    "                html_content.append('<div class=\"file-section\">')\n",
    "                html_content.append(f'<div class=\"file-header\">Processing: {html.escape(filename)}</div>')\n",
    "                html_content.append(f'<div class=\"page-info\">Document has {len(doc)} pages</div>')\n",
    "                \n",
    "                # Process pages\n",
    "                page_numbers = {}\n",
    "                \n",
    "                # Show initial items\n",
    "                for page_num in range(min(max_initial_items, len(doc))):\n",
    "                    page = doc.load_page(page_num)\n",
    "                    detected_numbers = extract_potential_page_numbers(page, filename)\n",
    "                    page_numbers[page_num] = detected_numbers\n",
    "                    html_content.append(\n",
    "                        f'<div class=\"page-info\">Page {page_num + 1}: '\n",
    "                        f'Detected numbers: {html.escape(str(detected_numbers))}</div>'\n",
    "                    )\n",
    "                    total_pages_processed += 1\n",
    "                \n",
    "                # Add remaining items in hidden div\n",
    "                if len(doc) > max_initial_items:\n",
    "                    html_content.append(f'<div id=\"{file_id}\" class=\"hidden\">')\n",
    "                    for page_num in range(max_initial_items, len(doc)):\n",
    "                        page = doc.load_page(page_num)\n",
    "                        detected_numbers = extract_potential_page_numbers(page, filename)\n",
    "                        page_numbers[page_num] = detected_numbers\n",
    "                        html_content.append(\n",
    "                            f'<div class=\"page-info\">Page {page_num + 1}: '\n",
    "                            f'Detected numbers: {html.escape(str(detected_numbers))}</div>'\n",
    "                        )\n",
    "                        total_pages_processed += 1\n",
    "                    html_content.append('</div>')\n",
    "                    html_content.append(\n",
    "                        f'<div><a class=\"show-more\" id=\"btn-{file_id}\" '\n",
    "                        f'onclick=\"toggleContent(\\'{file_id}\\')\">Show more</a></div>'\n",
    "                    )\n",
    "                \n",
    "                doc.close()\n",
    "                processed_files += 1\n",
    "                html_content.append('</div>')  # Close file-section\n",
    "                \n",
    "            except Exception as e:\n",
    "                html_content.append(\n",
    "                    f'<div class=\"error-message\">Error processing {html.escape(filename)}: {str(e)}</div>'\n",
    "                )\n",
    "                continue\n",
    "    \n",
    "    # Add summary section\n",
    "    html_content.append(\n",
    "        f'''\n",
    "        <div class=\"summary\">\n",
    "            <strong>Processing Summary:</strong><br>\n",
    "            Files processed: {processed_files}<br>\n",
    "            Total pages processed: {total_pages_processed}\n",
    "        </div>\n",
    "        '''\n",
    "    )\n",
    "    \n",
    "    html_content.append('</div>')\n",
    "    \n",
    "    # Display the HTML\n",
    "    display(HTML(''.join(html_content)))\n",
    "\n",
    "def run_page_detection(pdf_directory):\n",
    "    \"\"\"\n",
    "    Run page detection with directory validation.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(pdf_directory):\n",
    "        display(HTML(\n",
    "            '<div style=\"color: red; padding: 10px; border: 1px solid red;\">'\n",
    "            f'Error: Directory not found: {html.escape(pdf_directory)}'\n",
    "            '</div>'\n",
    "        ))\n",
    "        return\n",
    "    \n",
    "    print_detected_pages(pdf_directory)\n",
    "\n",
    "# Set directory and run\n",
    "pdf_directory = \"./data\"  # Replace with your actual directory path\n",
    "run_page_detection(pdf_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8239a8a",
   "metadata": {},
   "source": [
    "# Adjusting Context Size in Pattern Matching\n",
    "\n",
    "## Overview\n",
    "In the pattern matching function, you can control how much surrounding text (context) is displayed around each found pattern by adjusting the `context_size` parameter.\n",
    "\n",
    "## Current Setting\n",
    "```python\n",
    "context_size = 300  # Characters before and after match\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0edab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6 - Text Extraction and Pattern Matching (Detailed):\n",
    "def extract_text_from_docx(docx_path):\n",
    "    \"\"\"\n",
    "    Extract text from Word documents.\n",
    "    \n",
    "    Args:\n",
    "        docx_path (str): Path to DOCX file\n",
    "    \n",
    "    Returns:\n",
    "        str: Combined text from all paragraphs\n",
    "    \n",
    "    Raises:\n",
    "        Exception: If document cannot be read\n",
    "    \"\"\"\n",
    "    try:\n",
    "        doc = Document(docx_path)\n",
    "        full_text = []\n",
    "        for para in doc.paragraphs:\n",
    "            full_text.append(para.text)\n",
    "        return ' '.join(full_text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading DOCX file: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def find_patterns(text, patterns, page_number):\n",
    "    \"\"\"\n",
    "    Find patterns in text with context.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Text to search in\n",
    "        patterns (list): List of regex patterns\n",
    "        page_number (int): Current page number\n",
    "    \n",
    "    Returns:\n",
    "        list: Tuples of (match, context, page_number)\n",
    "    \"\"\"\n",
    "    matches = []\n",
    "    context_size = 300  # Characters before and after match\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        for match in re.finditer(pattern, text, re.IGNORECASE):\n",
    "            # Extract context around match\n",
    "            start = max(match.start() - context_size, 0)\n",
    "            end = min(match.end() + context_size, len(text))\n",
    "            context = text[start:end]\n",
    "            \n",
    "            matches.append((match.group(), context, page_number))\n",
    "    \n",
    "    return matches\n",
    "\n",
    "# Initialize storage\n",
    "content_by_year = defaultdict(str)\n",
    "print(\"Text extraction functions initialized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee7db61-943a-472e-8d0b-d76a4949b682",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 7 - Main Processing Loop (Detailed):\n",
    "# Process all files in directory\n",
    "print(\"Starting file processing...\")\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(('.pdf', '.docx')):\n",
    "        try:\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            print(f\"\\nProcessing: {filename}\")\n",
    "            \n",
    "            # Extract year and title from filename\n",
    "            year_match = re.match(r'\\d{4}', filename)\n",
    "            if not year_match:\n",
    "                print(f\"Warning: No year found in filename {filename}\")\n",
    "                continue\n",
    "                \n",
    "            year = year_match.group()\n",
    "            # Fix the title extraction\n",
    "            title = filename.replace(f\"{year}-\", \"\").replace(\"_searchable.pdf\", \"\").replace(\".pdf\", \"\").replace(\".docx\", \"\")\n",
    "            \n",
    "            # Initialize year in content_by_year if not exists\n",
    "            if year not in content_by_year:\n",
    "                content_by_year[year] = \"\"\n",
    "            \n",
    "            # Extract text based on file type\n",
    "            if filename.endswith('.pdf'):\n",
    "                pdf_text, page_numbers = extract_text_from_pdf(file_path)\n",
    "                text = ' '.join(pdf_text.values())\n",
    "            else:  # DOCX file\n",
    "                text = extract_text_from_docx(file_path)\n",
    "            \n",
    "            # Process patterns\n",
    "            all_matches = []\n",
    "            if filename.endswith('.pdf'):\n",
    "                for page_num, page_text in pdf_text.items():\n",
    "                    actual_page_num = page_numbers.get(page_num, page_num)\n",
    "                    matches = find_patterns(page_text, patterns, actual_page_num)\n",
    "                    all_matches.extend(matches)\n",
    "            else:\n",
    "                matches = find_patterns(text, patterns, None)\n",
    "                all_matches.extend(matches)\n",
    "            \n",
    "            # Store results with document header\n",
    "            content_by_year[year] += (\n",
    "                f\"\\n{'=' * 80}\\n\"\n",
    "                f\"Document: {filename}\\n\"\n",
    "                f\"Year: {year}\\n\"\n",
    "                f\"\\n{'=' * 80}\\n\"\n",
    "            )\n",
    "            \n",
    "            for match, context, page_num in all_matches:\n",
    "                content_by_year[year] += (\n",
    "                    f\"\\nTitle: {title}\\n\"\n",
    "                    f\"Year: {year}\\n\"\n",
    "                    f\"Pattern Found: {match}\\n\"\n",
    "                    f\"\\nContext:\\n\"\n",
    "                    f\"{context}\\n\"\n",
    "                    f\"Page Number: {page_num}\\n\"\n",
    "                    f\"{'-' * 80}\\n\"\n",
    "                )\n",
    "                \n",
    "            # Update pattern counts\n",
    "            for pattern in patterns:\n",
    "                for match, _, page_num in all_matches:\n",
    "                    if re.match(pattern, match, re.IGNORECASE):\n",
    "                        # Initialize nested dictionaries if they don't exist\n",
    "                        if pattern not in pattern_counts_by_year_title_page:\n",
    "                            pattern_counts_by_year_title_page[pattern] = {}\n",
    "                        if year not in pattern_counts_by_year_title_page[pattern]:\n",
    "                            pattern_counts_by_year_title_page[pattern][year] = {}\n",
    "                        if title not in pattern_counts_by_year_title_page[pattern][year]:\n",
    "                            pattern_counts_by_year_title_page[pattern][year][title] = {\n",
    "                                'pages': [], 'count': 0\n",
    "                            }\n",
    "                        if page_num:\n",
    "                            pattern_counts_by_year_title_page[pattern][year][title]['pages'].append(page_num)\n",
    "                        pattern_counts_by_year_title_page[pattern][year][title]['count'] += 1\n",
    "                        total_pattern_counts[pattern] += 1\n",
    "                        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {str(e)}\")\n",
    "            import traceback\n",
    "            print(traceback.format_exc())\n",
    "            continue\n",
    "\n",
    "print(\"\\nFile processing completed\")\n",
    "print(\"\\nPattern counts summary:\")\n",
    "for pattern, counts in pattern_counts_by_year_title_page.items():\n",
    "    print(f\"\\nPattern: {pattern}\")\n",
    "    for year, year_data in counts.items():\n",
    "        for title, data in year_data.items():\n",
    "            print(f\"Year: {year}, Title: {title}, Count: {data['count']}, Pages: {data['pages']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e05991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8 - Output Generation:\n",
    "# Save the combined output text as a single file, ordered by year\n",
    "output_file_path = os.path.join(directory, 'combined_output_test.txt')\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    for year in sorted(content_by_year.keys()):\n",
    "        output_file.write(f\"\\n\\n--- Year: {year} ---\\n\\n\")\n",
    "        output_file.write(content_by_year[year])\n",
    "    \n",
    "    # Append total counts of each pattern to the file\n",
    "    output_file.write(\"\\nTotal counts of each pattern across all files:\\n\")\n",
    "    output_file.write(\"=\" * 80 + \"\\n\")\n",
    "    for pattern, count in total_pattern_counts.items():\n",
    "        output_file.write(f\"{pattern}: {count}\\n\")\n",
    "    output_file.write(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "print(f\"Output saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636880d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9 - Results Display:\n",
    "# Create highlighted HTML output\n",
    "\n",
    "# Create the output content with highlighting\n",
    "output_content = \"\"\n",
    "result_count = 0\n",
    "max_results = 10\n",
    "\n",
    "# Add content to the string, ordered by year\n",
    "for year in sorted(content_by_year.keys()):\n",
    "    if result_count >= max_results:\n",
    "        break\n",
    "        \n",
    "    output_content += f\"\\n\\n--- Year: {year} ---\\n\\n\"\n",
    "    year_content = content_by_year[year]\n",
    "    \n",
    "    # Split content into individual results\n",
    "    sections = year_content.split(\"=\" * 80)\n",
    "    for section in sections:\n",
    "        if result_count >= max_results:\n",
    "            break\n",
    "            \n",
    "        if section.strip():  # if section is not empty\n",
    "            output_content += section + \"=\" * 80 + \"\\n\"\n",
    "            result_count += 1\n",
    "\n",
    "# Add total counts of each pattern\n",
    "output_content += \"\\nTotal counts of each pattern across all files:\\n\"\n",
    "output_content += \"=\" * 80 + \"\\n\"\n",
    "for pattern, count in total_pattern_counts.items():\n",
    "    output_content += f\"{pattern}: {count}\\n\"\n",
    "output_content += \"=\" * 80 + \"\\n\"\n",
    "\n",
    "# Add note about truncated results\n",
    "if result_count >= max_results:\n",
    "    output_content = f\"Showing first {max_results} results out of total matches.\\n\\n\" + output_content\n",
    "\n",
    "# Highlight patterns and labels\n",
    "def highlight_patterns_and_labels(text, patterns):\n",
    "    highlighted_text = text\n",
    "    \n",
    "    # Highlight patterns - using more contrast-friendly colors\n",
    "    for pattern in patterns:\n",
    "        matches = re.finditer(pattern, highlighted_text, re.IGNORECASE)\n",
    "        matches = list(matches)\n",
    "        for match in reversed(matches):\n",
    "            start, end = match.span()\n",
    "            match_text = highlighted_text[start:end]\n",
    "            highlighted_text = (\n",
    "                highlighted_text[:start] + \n",
    "                f'<span style=\"color: #FFB6C1; font-weight: bold; background-color: #4A312B; padding: 0 2px;\">{match_text}</span>' + \n",
    "                highlighted_text[end:]\n",
    "            )\n",
    "    \n",
    "    # Highlight labels with higher contrast colors\n",
    "    label_styles = {\n",
    "        \"Pattern:\": \"color: #ADD8E6; font-weight: bold; background-color: #2F4F4F; padding: 2px 5px; border-radius: 3px;\",\n",
    "        \"Context:\": \"color: #90EE90; font-weight: bold; background-color: #2F4F2F; padding: 2px 5px; border-radius: 3px;\",\n",
    "        \"Page Number:\": \"color: #DDA0DD; font-weight: bold; background-color: #4B0082; padding: 2px 5px; border-radius: 3px;\"\n",
    "    }\n",
    "    \n",
    "    for label, style in label_styles.items():\n",
    "        highlighted_text = highlighted_text.replace(\n",
    "            label,\n",
    "            f'<span style=\"{style}\">{label}</span>'\n",
    "        )\n",
    "    \n",
    "    return highlighted_text\n",
    "\n",
    "# Apply highlighting\n",
    "highlighted_content = highlight_patterns_and_labels(output_content, patterns)\n",
    "\n",
    "# Format for display with improved styling\n",
    "formatted_output = highlighted_content.replace('\\n', '<br>')\n",
    "formatted_output = f'''\n",
    "<div style=\"font-family: 'Courier New', monospace; \n",
    "            background-color: #1E1E1E; \n",
    "            border-radius: 8px; \n",
    "            margin: 10px 0;\">\n",
    "    <div style=\"color: #D3D3D3; \n",
    "                padding: 10px; \n",
    "                border-bottom: 1px solid #404040;\">\n",
    "        Showing first {max_results} results. Scroll to view content.\n",
    "    </div>\n",
    "    <div style=\"max-height: 500px; \n",
    "                overflow-y: auto; \n",
    "                background-color: #1E1E1E; \n",
    "                border: 1px solid #404040; \n",
    "                border-radius: 0 0 8px 8px;\">\n",
    "        <pre style=\"white-space: pre-wrap; \n",
    "                    font-family: 'Courier New', monospace; \n",
    "                    line-height: 1.5; \n",
    "                    color: #D3D3D3; \n",
    "                    padding: 15px; \n",
    "                    margin: 0;\n",
    "                    overflow-x: auto;\">\n",
    "            {formatted_output}\n",
    "        </pre>\n",
    "    </div>\n",
    "</div>\n",
    "'''\n",
    "\n",
    "# Add CSS to ensure consistent rendering\n",
    "css_styles = '''\n",
    "<style>\n",
    "    .jupyter-notebook .output_html {\n",
    "        background-color: transparent !important;\n",
    "    }\n",
    "    .output_area pre {\n",
    "        background-color: #1E1E1E !important;\n",
    "    }\n",
    "    .output_scroll {\n",
    "        box-shadow: none !important;\n",
    "    }\n",
    "</style>\n",
    "'''\n",
    "\n",
    "# Display in Jupyter notebook with consistent styling\n",
    "display(HTML(css_styles + formatted_output))\n",
    "\n",
    "# Save to file (without HTML formatting)\n",
    "output_file_path = os.path.join(directory, 'combined_output_test.txt')\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    # Remove HTML tags for file output\n",
    "    clean_content = re.sub(r'<[^>]+>', '', output_content)\n",
    "    output_file.write(clean_content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b3e605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10 - Data Analysis:\n",
    "try:\n",
    "    # Convert the counts to a DataFrame for easier plotting while including page numbers\n",
    "    df_list = []\n",
    "    for pattern, year_data in pattern_counts_by_year_title_page.items():\n",
    "        for year, title_data in year_data.items():\n",
    "            for title, page_info in title_data.items():\n",
    "                df_list.append({\n",
    "                    'Pattern': pattern, \n",
    "                    'Year': year, \n",
    "                    'Title': title, \n",
    "                    'Page': page_info['pages'], \n",
    "                    'Count': page_info['count']\n",
    "                })\n",
    "\n",
    "    if not df_list:\n",
    "        print(\"No matches found in any documents.\")\n",
    "    else:\n",
    "        df = pd.DataFrame(df_list)\n",
    "        \n",
    "        # Display DataFrame with better formatting\n",
    "        pd.set_option('display.max_columns', None)\n",
    "        pd.set_option('display.expand_frame_repr', False)\n",
    "        pd.set_option('display.max_colwidth', None)\n",
    "        \n",
    "        print(\"\\nDetailed Pattern Analysis DataFrame:\")\n",
    "        print(\"=====================================\")\n",
    "        print(df.to_string())\n",
    "        print(\"\\n\")\n",
    "\n",
    "        # Aggregate counts by year, title, pattern with page information\n",
    "        df_agg = df.groupby(['Pattern', 'Year', 'Title']).agg({\n",
    "            'Page': lambda x: list(set([item for sublist in x for item in (sublist if isinstance(sublist, list) else [sublist])])),\n",
    "            'Count': 'sum'\n",
    "        }).reset_index()\n",
    "\n",
    "        # Calculate total matches per title\n",
    "        total_matches_per_title = df_agg.groupby(['Year', 'Title'])['Count'].sum().reset_index(name='TotalMatches')\n",
    "\n",
    "        # Merge the total matches back into df_agg\n",
    "        df_agg = df_agg.merge(total_matches_per_title, on=['Year', 'Title'])\n",
    "\n",
    "        # Create the summary column\n",
    "        df_agg['Year-Title-Page-Count'] = df_agg.apply(\n",
    "            lambda x: f\"{x['Year']}: {x['Title']} (Total: {x['TotalMatches']}) Pages: {', '.join(map(str, x['Page']))}\", \n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        # Final display\n",
    "        print(\"\\nAggregated Results:\")\n",
    "        print(\"===================\")\n",
    "        print(df_agg[['Pattern', 'Year-Title-Page-Count', 'Count']])\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in data analysis: {str(e)}\")\n",
    "    import traceback\n",
    "    print(traceback.format_exc())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbf472a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11 - Visualization:\n",
    "# Aggregate data by year first\n",
    "yearly_data = df_agg.copy()\n",
    "yearly_data['Year'] = yearly_data['Year-Title-Page-Count'].str[:4]  # Extract year\n",
    "yearly_totals = yearly_data.groupby(['Year', 'Pattern'])['Count'].sum().reset_index()\n",
    "\n",
    "# Create the stacked bar plot\n",
    "plt.figure(figsize=(14, 8))\n",
    "df_pivot = yearly_totals.pivot(index='Year', columns='Pattern', values='Count')\n",
    "ax = df_pivot.plot(kind='bar', stacked=True)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Pattern Occurrences by Year', fontsize=14, pad=20)\n",
    "plt.xlabel('Year', fontsize=12)\n",
    "plt.ylabel('Total Occurrences', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Enhance the legend\n",
    "plt.legend(title='Search Patterns', \n",
    "          bbox_to_anchor=(1.05, 1), \n",
    "          loc='upper left',\n",
    "          borderaxespad=0.)\n",
    "\n",
    "# Add total counts as text\n",
    "total_counts_text = \"Total counts across all years:\\n\"\n",
    "total_counts_text += \"\\n\".join([f\"{pattern}: {count}\" \n",
    "                               for pattern, count in total_pattern_counts.items()])\n",
    "\n",
    "# Position the text box\n",
    "plt.text(1.05, 0.5, total_counts_text,\n",
    "         bbox=dict(facecolor='white', alpha=0.8, edgecolor='gray'),\n",
    "         transform=ax.transAxes,\n",
    "         verticalalignment='center')\n",
    "\n",
    "# Add value labels on the bars\n",
    "for c in ax.containers:\n",
    "    # Add labels only for non-zero values\n",
    "    ax.bar_label(c, label_type='center', fmt='%.0f')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(right=0.85)\n",
    "\n",
    "# Save and display the plot\n",
    "stacked_bar_path = os.path.join(directory, 'yearly_pattern_distribution.png')\n",
    "plt.savefig(stacked_bar_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Create and save detailed Excel report\n",
    "excel_path = os.path.join(directory, 'pattern_analysis_report.xlsx')\n",
    "with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:\n",
    "    # Save yearly totals\n",
    "    yearly_totals_wide = yearly_totals.pivot(index='Year', \n",
    "                                           columns='Pattern', \n",
    "                                           values='Count').fillna(0)\n",
    "    yearly_totals_wide.to_excel(writer, sheet_name='Yearly Totals')\n",
    "    \n",
    "    # Save detailed analysis\n",
    "    df.to_excel(writer, sheet_name='Detailed Analysis', index=False)\n",
    "    \n",
    "    # Format the Excel file\n",
    "    workbook = writer.book\n",
    "    for sheet_name in workbook.sheetnames:\n",
    "        worksheet = workbook[sheet_name]\n",
    "        for column in worksheet.columns:\n",
    "            max_length = 0\n",
    "            column = [cell for cell in column]\n",
    "            for cell in column:\n",
    "                try:\n",
    "                    if len(str(cell.value)) > max_length:\n",
    "                        max_length = len(str(cell.value))\n",
    "                except:\n",
    "                    pass\n",
    "            adjusted_width = (max_length + 2)\n",
    "            worksheet.column_dimensions[column[0].column_letter].width = adjusted_width\n",
    "\n",
    "print(f\"\\nAnalysis has been saved to: {excel_path}\")\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"\\nYearly Pattern Distribution:\")\n",
    "print(yearly_totals_wide)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
