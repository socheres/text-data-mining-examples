{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369f64ab-d58b-4bf3-aaa6-83f9bb38818c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Introduction and Setup\n",
    "\"\"\"\n",
    "# ü§ñ Multi-Model LLM Comparison Tool\n",
    "## Google Colab Tutorial\n",
    "\n",
    "Learn how to compare responses from multiple AI models and generate professional PDF reports!\n",
    "\n",
    "What you'll learn:\n",
    "- Connect to OpenRouter API (access to many AI models)\n",
    "- Query multiple models simultaneously\n",
    "- Compare responses side by side\n",
    "- Generate professional PDF reports\n",
    "\"\"\"\n",
    "\n",
    "print(\"üéì Welcome to AI Model Comparison with PDF Reports!\")\n",
    "print(\"Let's compare AI models and create professional documentation!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ce9471-1d2a-43ec-8a5e-9d885e3bcc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Install and Import Everything\n",
    "# Install required packages\n",
    "!pip install requests reportlab\n",
    "\n",
    "# Import all required libraries\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import html\n",
    "import textwrap\n",
    "from datetime import datetime\n",
    "from typing import List, Dict\n",
    "\n",
    "# ReportLab imports for PDF generation\n",
    "from reportlab.lib.pagesizes import letter, A4\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.units import inch\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, PageBreak\n",
    "from reportlab.lib import colors\n",
    "from reportlab.lib.enums import TA_LEFT, TA_CENTER, TA_JUSTIFY\n",
    "\n",
    "print(\"‚úÖ All packages installed and imported!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c236ed6e-c5f3-407e-a233-44069ccfd7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Complete AI Comparison Class\n",
    "class AIModelComparison:\n",
    "    def __init__(self, api_key):\n",
    "        \"\"\"Initialize with your OpenRouter API key\"\"\"\n",
    "        self.api_key = api_key\n",
    "        self.base_url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "        self.headers = {\n",
    "            \"Authorization\": f\"Bearer {api_key}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        \n",
    "        # Popular models that work well\n",
    "        self.models = [\n",
    "            \"anthropic/claude-3.5-sonnet\",\n",
    "            \"meta-llama/llama-3.1-70b-instruct\",\n",
    "            \"openai/gpt-4.1-mini\",\n",
    "            \"anthropic/claude-sonnet-4\",\n",
    "            \"google/gemini-2.5-flash\",\n",
    "            \"qwen/qwen2.5-vl-72b-instruct\"\n",
    "        ]\n",
    "        \n",
    "    def query_model(self, model: str, prompt: str, max_tokens: int = 1500) -> Dict:\n",
    "        \"\"\"Query a specific model\"\"\"\n",
    "        payload = {\n",
    "            \"model\": model,\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"temperature\": 0.7\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(self.base_url, headers=self.headers, json=payload, timeout=30)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                return {\n",
    "                    \"model\": model,\n",
    "                    \"success\": True,\n",
    "                    \"response\": data[\"choices\"][0][\"message\"][\"content\"].strip(),\n",
    "                    \"tokens_used\": data.get(\"usage\", {}).get(\"total_tokens\", \"N/A\"),\n",
    "                    \"error\": None\n",
    "                }\n",
    "            else:\n",
    "                return {\n",
    "                    \"model\": model,\n",
    "                    \"success\": False,\n",
    "                    \"response\": f\"Error: {response.status_code}\",\n",
    "                    \"tokens_used\": \"N/A\",\n",
    "                    \"error\": response.text\n",
    "                }\n",
    "                \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"model\": model,\n",
    "                \"success\": False,\n",
    "                \"response\": f\"Exception: {str(e)}\",\n",
    "                \"tokens_used\": \"N/A\",\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "    \n",
    "    def query_multiple_models(self, prompt: str, max_tokens: int = 1500, delay: float = 0.5) -> List[Dict]:\n",
    "        \"\"\"Query multiple models with the same prompt\"\"\"\n",
    "        responses = []\n",
    "        \n",
    "        print(f\"ü§ñ Querying {len(self.models)} models...\")\n",
    "        print(f\"üìù Prompt: {prompt[:100]}...\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        for i, model in enumerate(self.models, 1):\n",
    "            print(f\"[{i}/{len(self.models)}] Querying {model}...\", end=\" \")\n",
    "            \n",
    "            response = self.query_model(model, prompt, max_tokens)\n",
    "            responses.append(response)\n",
    "            \n",
    "            if response[\"success\"]:\n",
    "                print(\"‚úÖ\")\n",
    "            else:\n",
    "                print(\"‚ùå\")\n",
    "            \n",
    "            # Add delay to avoid rate limiting\n",
    "            if i < len(self.models):\n",
    "                time.sleep(delay)\n",
    "        \n",
    "        return responses\n",
    "    \n",
    "    def display_responses(self, responses: List[Dict], prompt: str):\n",
    "        \"\"\"Display responses in a nice readable format\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 120)\n",
    "        print(f\"üïí RESULTS - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        print(\"=\" * 120)\n",
    "        print(f\"üìù ORIGINAL PROMPT: {prompt}\")\n",
    "        print(\"=\" * 120)\n",
    "        \n",
    "        # Calculate column width\n",
    "        col_width = max(35, max(len(r[\"model\"]) for r in responses) + 5)\n",
    "        \n",
    "        # Header\n",
    "        header = f\"{'MODEL':<{col_width}} | {'STATUS':<8} | {'TOKENS':<8} | RESPONSE\"\n",
    "        print(header)\n",
    "        print(\"-\" * len(header))\n",
    "        \n",
    "        for response in responses:\n",
    "            model_name = response[\"model\"]\n",
    "            status = \"‚úÖ OK\" if response[\"success\"] else \"‚ùå FAIL\"\n",
    "            tokens = str(response[\"tokens_used\"])\n",
    "            resp_text = response[\"response\"]\n",
    "            \n",
    "            # Truncate long responses for table view\n",
    "            if len(resp_text) > 80:\n",
    "                resp_preview = resp_text[:77] + \"...\"\n",
    "            else:\n",
    "                resp_preview = resp_text\n",
    "            \n",
    "            # Replace newlines with spaces for table format\n",
    "            resp_preview = resp_preview.replace('\\n', ' ').replace('\\r', ' ')\n",
    "            \n",
    "            print(f\"{model_name:<{col_width}} | {status:<8} | {tokens:<8} | {resp_preview}\")\n",
    "        \n",
    "        print(\"=\" * 120)\n",
    "        \n",
    "        # Detailed responses\n",
    "        print(\"\\nüìã DETAILED RESPONSES:\")\n",
    "        print(\"=\" * 120)\n",
    "        \n",
    "        for i, response in enumerate(responses, 1):\n",
    "            print(f\"\\n[{i}] ü§ñ MODEL: {response['model']}\")\n",
    "            print(f\"üìä STATUS: {'‚úÖ Success' if response['success'] else '‚ùå Failed'}\")\n",
    "            print(f\"üî¢ TOKENS: {response['tokens_used']}\")\n",
    "            print(\"üìÑ RESPONSE:\")\n",
    "            print(\"-\" * 60)\n",
    "            print(response[\"response\"])\n",
    "            print(\"-\" * 60)\n",
    "\n",
    "print(\"‚úÖ AIModelComparison class ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ad9de1-0491-4eb2-8dad-66d99f7dd75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: PDF Generation Methods\n",
    "\n",
    "def save_to_pdf_columns(self, responses: List[Dict], prompt: str, filename: str = None):\n",
    "    \"\"\"Save responses to PDF with 2-column layout - ENHANCED WITH FALLBACKS\"\"\"\n",
    "    if filename is None:\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        filename = f\"openrouter_responses_{timestamp}.pdf\"\n",
    "    \n",
    "    def clean_text_for_pdf(text: str, max_length: int = None) -> str:\n",
    "        \"\"\"Advanced text cleaning for PDF generation with length control\"\"\"\n",
    "        if not text:\n",
    "            return \"No content available\"\n",
    "        \n",
    "        # Convert to string\n",
    "        text = str(text)\n",
    "        \n",
    "        # Remove null bytes and problematic control characters\n",
    "        text = text.replace('\\x00', '').replace('\\x08', '').replace('\\x0b', '').replace('\\x0c', '')\n",
    "        text = text.replace('\\x0e', '').replace('\\x0f', '').replace('\\x10', '').replace('\\x11', '')\n",
    "        \n",
    "        # Replace problematic characters with safe alternatives\n",
    "        replacements = {\n",
    "            '&': 'and',\n",
    "            '<': '[',\n",
    "            '>': ']',\n",
    "            '\"': \"'\",\n",
    "            '\\\\': '/',\n",
    "            '\\u2018': \"'\",  # Left single quote\n",
    "            '\\u2019': \"'\",  # Right single quote\n",
    "            '\\u201c': '\"',  # Left double quote\n",
    "            '\\u201d': '\"',  # Right double quote\n",
    "            '\\u2013': '-',  # En dash\n",
    "            '\\u2014': '-',  # Em dash\n",
    "            '\\u2026': '...',  # Ellipsis\n",
    "        }\n",
    "        \n",
    "        for old, new in replacements.items():\n",
    "            text = text.replace(old, new)\n",
    "        \n",
    "        # Preserve line breaks for readability\n",
    "        text = text.replace('\\n', ' | ')\n",
    "        \n",
    "        # Remove non-printable characters but keep basic punctuation\n",
    "        text = ''.join(char for char in text if ord(char) >= 32 and ord(char) <= 126)\n",
    "        \n",
    "        # Apply length limit if specified\n",
    "        if max_length and len(text) > max_length:\n",
    "            text = text[:max_length] + \"... [truncated]\"\n",
    "        \n",
    "        return text.strip() or \"No content\"\n",
    "    \n",
    "    def create_enhanced_table_pdf():\n",
    "        \"\"\"Create enhanced table-based PDF with smart content handling\"\"\"\n",
    "        try:\n",
    "            print(f\"üéØ Creating enhanced PDF: {filename}\")\n",
    "            \n",
    "            # Create PDF document with optimized settings\n",
    "            doc = SimpleDocTemplate(\n",
    "                filename,\n",
    "                pagesize=A4,\n",
    "                rightMargin=25,\n",
    "                leftMargin=25,\n",
    "                topMargin=40,\n",
    "                bottomMargin=40\n",
    "            )\n",
    "            \n",
    "            story = []\n",
    "            styles = getSampleStyleSheet()\n",
    "            \n",
    "            # Custom styles with better sizing\n",
    "            title_style = ParagraphStyle(\n",
    "                'EnhancedTitle',\n",
    "                parent=styles['Title'],\n",
    "                fontSize=16,\n",
    "                spaceAfter=15,\n",
    "                alignment=TA_CENTER,\n",
    "                textColor=colors.darkblue\n",
    "            )\n",
    "            \n",
    "            heading_style = ParagraphStyle(\n",
    "                'EnhancedHeading',\n",
    "                parent=styles['Heading2'],\n",
    "                fontSize=12,\n",
    "                spaceAfter=8,\n",
    "                spaceBefore=12,\n",
    "                textColor=colors.darkblue\n",
    "            )\n",
    "            \n",
    "            model_style = ParagraphStyle(\n",
    "                'EnhancedModel',\n",
    "                parent=styles['Normal'],\n",
    "                fontSize=9,\n",
    "                textColor=colors.darkblue,\n",
    "                alignment=TA_LEFT,\n",
    "                fontName='Helvetica-Bold',\n",
    "                wordWrap='LTR'\n",
    "            )\n",
    "            \n",
    "            response_style = ParagraphStyle(\n",
    "                'EnhancedResponse',\n",
    "                parent=styles['Normal'],\n",
    "                fontSize=8,\n",
    "                alignment=TA_LEFT,\n",
    "                leftIndent=2,\n",
    "                rightIndent=2,\n",
    "                spaceAfter=1,\n",
    "                wordWrap='LTR'\n",
    "            )\n",
    "            \n",
    "            # Title and metadata\n",
    "            story.append(Paragraph(\"Multi-Model AI Comparison Report\", title_style))\n",
    "            story.append(Spacer(1, 10))\n",
    "            \n",
    "            # Summary info\n",
    "            story.append(Paragraph(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\", styles['Normal']))\n",
    "            story.append(Paragraph(f\"Total Models: {len(responses)}\", styles['Normal']))\n",
    "            \n",
    "            successful = sum(1 for r in responses if r[\"success\"])\n",
    "            story.append(Paragraph(f\"Successful: {successful}/{len(responses)}\", styles['Normal']))\n",
    "            story.append(Spacer(1, 12))\n",
    "            \n",
    "            # Original prompt (truncated for space)\n",
    "            story.append(Paragraph(\"Prompt\", heading_style))\n",
    "            clean_prompt = clean_text_for_pdf(prompt, 500)  # Limit prompt length\n",
    "            story.append(Paragraph(clean_prompt, styles['Normal']))\n",
    "            story.append(Spacer(1, 15))\n",
    "            \n",
    "            # Responses section\n",
    "            story.append(Paragraph(\"Model Responses\", heading_style))\n",
    "            \n",
    "            # Smart pagination - split responses into chunks if too many\n",
    "            chunk_size = 10  # Max responses per table to prevent overflow\n",
    "            response_chunks = [responses[i:i + chunk_size] for i in range(0, len(responses), chunk_size)]\n",
    "            \n",
    "            for chunk_idx, chunk in enumerate(response_chunks):\n",
    "                if chunk_idx > 0:\n",
    "                    story.append(PageBreak())  # New page for additional chunks\n",
    "                \n",
    "                # Prepare table data for this chunk\n",
    "                table_data = []\n",
    "                \n",
    "                # Header row\n",
    "                table_data.append([\n",
    "                    Paragraph(\"Model\", model_style),\n",
    "                    Paragraph(\"Response\", model_style)\n",
    "                ])\n",
    "                \n",
    "                # Data rows with smart length management\n",
    "                for response in chunk:\n",
    "                    # Model name with status\n",
    "                    model_name = response[\"model\"].split('/')[-1]\n",
    "                    status_symbol = \"[OK]\" if response[\"success\"] else \"[ERR]\"\n",
    "                    tokens = f\"({response['tokens_used']})\" if response[\"success\"] and response[\"tokens_used\"] != \"N/A\" else \"\"\n",
    "                    \n",
    "                    model_cell_text = f\"{model_name} {status_symbol} {tokens}\"\n",
    "                    model_cell_clean = clean_text_for_pdf(model_cell_text, 100)\n",
    "                    \n",
    "                    # Response content with adaptive length based on number of responses\n",
    "                    max_response_length = 800 if len(chunk) <= 5 else 400  # Longer responses for fewer models\n",
    "                    \n",
    "                    if response[\"success\"]:\n",
    "                        response_text = clean_text_for_pdf(response[\"response\"])\n",
    "                    else:\n",
    "                        error_text = response.get(\"error\", response[\"response\"])\n",
    "                        response_text = f\"Error: {clean_text_for_pdf(error_text)}\"\n",
    "                    \n",
    "                    # Add to table\n",
    "                    table_data.append([\n",
    "                        Paragraph(model_cell_clean, model_style),\n",
    "                        Paragraph(response_text, response_style)\n",
    "                    ])\n",
    "                \n",
    "                # Create table with dynamic column widths\n",
    "                available_width = A4[0] - 50  # Account for margins\n",
    "                col_widths = [available_width * 0.25, available_width * 0.75]  # 25/75 split\n",
    "                \n",
    "                comparison_table = Table(table_data, colWidths=col_widths, repeatRows=1)\n",
    "                \n",
    "                # Enhanced table styling\n",
    "                table_style = [\n",
    "                    # Header styling\n",
    "                    ('BACKGROUND', (0, 0), (-1, 0), colors.darkblue),\n",
    "                    ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),\n",
    "                    ('ALIGN', (0, 0), (-1, 0), 'CENTER'),\n",
    "                    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "                    ('FONTSIZE', (0, 0), (-1, 0), 10),\n",
    "                    ('BOTTOMPADDING', (0, 0), (-1, 0), 8),\n",
    "                    ('TOPPADDING', (0, 0), (-1, 0), 8),\n",
    "                    \n",
    "                    # Data cells\n",
    "                    ('BACKGROUND', (0, 1), (-1, -1), colors.white),\n",
    "                    ('TEXTCOLOR', (0, 1), (-1, -1), colors.black),\n",
    "                    ('ALIGN', (0, 1), (-1, -1), 'LEFT'),\n",
    "                    ('VALIGN', (0, 1), (-1, -1), 'TOP'),\n",
    "                    ('FONTNAME', (0, 1), (-1, -1), 'Helvetica'),\n",
    "                    ('FONTSIZE', (0, 1), (-1, -1), 8),\n",
    "                    ('LEFTPADDING', (0, 1), (-1, -1), 5),\n",
    "                    ('RIGHTPADDING', (0, 1), (-1, -1), 5),\n",
    "                    ('TOPPADDING', (0, 1), (-1, -1), 6),\n",
    "                    ('BOTTOMPADDING', (0, 1), (-1, -1), 6),\n",
    "                    \n",
    "                    # Borders\n",
    "                    ('GRID', (0, 0), (-1, -1), 0.5, colors.grey),\n",
    "                    ('LINEBELOW', (0, 0), (-1, 0), 2, colors.darkblue),\n",
    "                ]\n",
    "                \n",
    "                # Add alternating row colors\n",
    "                for i in range(1, len(table_data)):\n",
    "                    if i % 2 == 0:\n",
    "                        table_style.append(('BACKGROUND', (0, i), (-1, i), colors.lightgrey))\n",
    "                \n",
    "                comparison_table.setStyle(TableStyle(table_style))\n",
    "                story.append(comparison_table)\n",
    "                story.append(Spacer(1, 15))\n",
    "            \n",
    "            # Footer\n",
    "            footer_text = f\"Report generated on {datetime.now().strftime('%Y-%m-%d at %H:%M:%S')}\"\n",
    "            story.append(Paragraph(footer_text, styles['Normal']))\n",
    "            \n",
    "            # Build PDF\n",
    "            doc.build(story)\n",
    "            return filename\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Enhanced PDF creation failed: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def create_simple_fallback_pdf():\n",
    "        \"\"\"Fallback: Create simple text-based PDF\"\"\"\n",
    "        try:\n",
    "            simple_filename = filename.replace('.pdf', '_simple.pdf')\n",
    "            print(f\"üîÑ Creating simple fallback PDF: {simple_filename}\")\n",
    "            \n",
    "            doc = SimpleDocTemplate(\n",
    "                simple_filename,\n",
    "                pagesize=A4,\n",
    "                rightMargin=40,\n",
    "                leftMargin=40,\n",
    "                topMargin=50,\n",
    "                bottomMargin=50\n",
    "            )\n",
    "            \n",
    "            story = []\n",
    "            styles = getSampleStyleSheet()\n",
    "            \n",
    "            # Title\n",
    "            story.append(Paragraph(\"Multi-Model AI Comparison Report\", styles['Title']))\n",
    "            story.append(Spacer(1, 12))\n",
    "            \n",
    "            # Basic info\n",
    "            story.append(Paragraph(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\", styles['Normal']))\n",
    "            story.append(Spacer(1, 10))\n",
    "            \n",
    "            # Prompt\n",
    "            story.append(Paragraph(\"Prompt:\", styles['Heading2']))\n",
    "            story.append(Paragraph(clean_text_for_pdf(prompt, 1000), styles['Normal']))\n",
    "            story.append(Spacer(1, 15))\n",
    "            \n",
    "            # Responses\n",
    "            story.append(Paragraph(\"Responses:\", styles['Heading2']))\n",
    "            \n",
    "            for i, response in enumerate(responses):\n",
    "                model_name = response[\"model\"].split('/')[-1]\n",
    "                status = \"Success\" if response[\"success\"] else \"Failed\"\n",
    "                \n",
    "                # Model header\n",
    "                story.append(Paragraph(f\"{i+1}. {model_name} - {status}\", styles['Heading3']))\n",
    "                \n",
    "                # Response content\n",
    "                if response[\"success\"]:\n",
    "                    content = clean_text_for_pdf(response[\"response\"], 2000)\n",
    "                else:\n",
    "                    content = f\"Error: {clean_text_for_pdf(response['response'], 500)}\"\n",
    "                \n",
    "                story.append(Paragraph(content, styles['Normal']))\n",
    "                story.append(Spacer(1, 10))\n",
    "            \n",
    "            doc.build(story)\n",
    "            return simple_filename\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Simple PDF creation failed: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def create_text_fallback():\n",
    "        \"\"\"Final fallback: Create text file\"\"\"\n",
    "        try:\n",
    "            text_filename = filename.replace('.pdf', '.txt')\n",
    "            print(f\"üîÑ Creating text fallback: {text_filename}\")\n",
    "            \n",
    "            with open(text_filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(\"Multi-Model AI Comparison Report\\n\")\n",
    "                f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "                f.write(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "                f.write(f\"Total Models: {len(responses)}\\n\\n\")\n",
    "                \n",
    "                f.write(\"PROMPT:\\n\")\n",
    "                f.write(\"-\" * 20 + \"\\n\")\n",
    "                f.write(prompt + \"\\n\\n\")\n",
    "                \n",
    "                f.write(\"RESPONSES:\\n\")\n",
    "                f.write(\"-\" * 20 + \"\\n\\n\")\n",
    "                \n",
    "                for i, response in enumerate(responses):\n",
    "                    model_name = response[\"model\"].split('/')[-1]\n",
    "                    status = \"SUCCESS\" if response[\"success\"] else \"FAILED\"\n",
    "                    \n",
    "                    f.write(f\"{i+1}. {model_name} - {status}\\n\")\n",
    "                    f.write(\"-\" * 30 + \"\\n\")\n",
    "                    \n",
    "                    if response[\"success\"]:\n",
    "                        f.write(response[\"response\"])\n",
    "                    else:\n",
    "                        f.write(f\"Error: {response['response']}\")\n",
    "                    \n",
    "                    f.write(\"\\n\\n\" + \"=\"*50 + \"\\n\\n\")\n",
    "            \n",
    "            return text_filename\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Text fallback failed: {e}\")\n",
    "            return None\n",
    "    \n",
    "    # Main execution with cascading fallbacks\n",
    "    try:\n",
    "        # Strategy 1: Enhanced table PDF\n",
    "        result = create_enhanced_table_pdf()\n",
    "        if result:\n",
    "            print(f\"‚úÖ Enhanced PDF created successfully: {result}\")\n",
    "            print(\"üìã Features:\")\n",
    "            print(\"  ‚Ä¢ Smart content pagination\")\n",
    "            print(\"  ‚Ä¢ Adaptive text truncation\")\n",
    "            print(\"  ‚Ä¢ Professional 2-column layout\")\n",
    "            print(\"  ‚Ä¢ Status indicators and token counts\")\n",
    "            return result\n",
    "        \n",
    "        # Strategy 2: Simple PDF fallback\n",
    "        print(\"üîÑ Trying simple PDF format...\")\n",
    "        result = create_simple_fallback_pdf()\n",
    "        if result:\n",
    "            print(f\"‚úÖ Simple PDF created: {result}\")\n",
    "            return result\n",
    "        \n",
    "        # Strategy 3: Text file fallback\n",
    "        print(\"üîÑ Trying text file format...\")\n",
    "        result = create_text_fallback()\n",
    "        if result:\n",
    "            print(f\"‚úÖ Text file created: {result}\")\n",
    "            return result\n",
    "        \n",
    "        print(\"‚ùå All PDF creation methods failed\")\n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Unexpected error in PDF generation: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# Replace the PDF method with the enhanced version\n",
    "AIModelComparison.save_to_pdf = save_to_pdf_columns\n",
    "\n",
    "print(\"‚úÖ ENHANCED PDF Generator with Fallbacks Ready!\")\n",
    "print(\"üéØ New Features:\")\n",
    "print(\"  üìä Smart content pagination (prevents overflow)\")\n",
    "print(\"  üìè Adaptive text truncation based on content volume\")\n",
    "print(\"  üîÑ Triple fallback system (Enhanced ‚Üí Simple ‚Üí Text)\")\n",
    "print(\"  üõ°Ô∏è Robust error handling and recovery\")\n",
    "print(\"  üìã Professional table layouts with alternating colors\")\n",
    "print(\"  ‚ö° Optimized for various content sizes\")\n",
    "print(\"  üîß Detailed debugging and progress feedback\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2932326-5269-4c04-a842-cd9938d89ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: JSON Export Method\n",
    "def save_to_json(self, responses: List[Dict], prompt: str, filename: str = None):\n",
    "    \"\"\"Save responses to a JSON file\"\"\"\n",
    "    if filename is None:\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        filename = f\"openrouter_responses_{timestamp}.json\"\n",
    "    \n",
    "    data = {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"prompt\": prompt,\n",
    "        \"responses\": responses,\n",
    "        \"statistics\": {\n",
    "            \"total_models\": len(responses),\n",
    "            \"successful_responses\": sum(1 for r in responses if r[\"success\"]),\n",
    "            \"failed_responses\": sum(1 for r in responses if not r[\"success\"]),\n",
    "            \"total_tokens\": sum(int(r[\"tokens_used\"]) for r in responses if str(r[\"tokens_used\"]).isdigit())\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"üíæ JSON saved: {filename}\")\n",
    "    return filename\n",
    "\n",
    "# Add to class\n",
    "AIModelComparison.save_to_json = save_to_json\n",
    "\n",
    "print(\"‚úÖ JSON export method added!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358a977c-e583-4e17-884c-3352b6a682ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Setup API Key\n",
    "# Get your free API key from: https://openrouter.ai/\n",
    "api_key = os.getenv('OPENROUTER_API_KEY')\n",
    "\n",
    "if not api_key:\n",
    "    api_key = input(\"Enter your OpenRouter API key: \").strip()\n",
    "\n",
    "if api_key:\n",
    "    print(\"üîë API key configured!\")\n",
    "    ai = AIModelComparison(api_key)\n",
    "    print(f\"üöÄ AI assistant ready with {len(ai.models)} models!\")\n",
    "else:\n",
    "    print(\"‚ùå Need API key to continue. Get one from: https://openrouter.ai/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dc2520-8c2d-4413-a9c8-d215112838e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Interactive Mode\n",
    "def interactive_comparison_enhanced():\n",
    "    \"\"\"Interactive mode with enhanced 2-column PDF\"\"\"\n",
    "    if 'ai' not in globals():\n",
    "        print(\"‚ùå AI assistant not found\")\n",
    "        return\n",
    "    \n",
    "    print(\"üéÆ Enhanced Interactive AI Model Comparison\")\n",
    "    print(\"üìã New Feature: 2-Column PDF (Model | Full Response)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    user_prompt = input(\"Enter your question: \").strip()\n",
    "    \n",
    "    if not user_prompt:\n",
    "        print(\"‚ùå Empty prompt!\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        max_tokens = int(input(\"Max tokens (default 800): \") or 800)\n",
    "    except ValueError:\n",
    "        max_tokens = 800\n",
    "    \n",
    "    # Query all models\n",
    "    print(\"\\nü§ñ Querying all models...\")\n",
    "    results = ai.query_multiple_models(user_prompt, max_tokens)\n",
    "    \n",
    "    # Display results\n",
    "    ai.display_responses(results, user_prompt)\n",
    "    \n",
    "    # Ask about saving\n",
    "    save_files = input(\"\\nüíæ Generate enhanced 2-column PDF report? (y/n): \").lower().strip()\n",
    "    \n",
    "    if save_files == 'y':\n",
    "        pdf_file = ai.save_to_pdf(results, user_prompt)\n",
    "        json_file = ai.save_to_json(results, user_prompt)\n",
    "        print(f\"\\n‚úÖ Reports saved:\")\n",
    "        print(f\"  üìÑ PDF (2-column): {pdf_file}\")\n",
    "        print(f\"  üíæ JSON: {json_file}\")\n",
    "    \n",
    "    print(\"‚ú® Enhanced comparison completed!\")\n",
    "\n",
    "print(\"üéâ Enhanced interactive mode ready!\")\n",
    "print(\"üí° Call: interactive_comparison_enhanced()\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7097fa8-4c60-4208-a27c-1f88287bad2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Execute interactive Mode\n",
    "interactive_comparison_enhanced()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69c15b5-4265-4055-819c-bf530dc570bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
