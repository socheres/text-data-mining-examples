{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "369f64ab-d58b-4bf3-aaa6-83f9bb38818c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéì Welcome to AI Model Comparison with PDF Reports!\n",
      "Let's compare AI models and create professional documentation!\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Introduction and Setup\n",
    "\"\"\"\n",
    "# ü§ñ Multi-Model LLM Comparison Tool\n",
    "## Google Colab Tutorial\n",
    "\n",
    "Learn how to compare responses from multiple AI models and generate professional PDF reports!\n",
    "\n",
    "What you'll learn:\n",
    "- Connect to OpenRouter API (access to many AI models)\n",
    "- Query multiple models simultaneously\n",
    "- Compare responses side by side\n",
    "- Generate professional PDF reports\n",
    "\"\"\"\n",
    "\n",
    "print(\"üéì Welcome to AI Model Comparison with PDF Reports!\")\n",
    "print(\"Let's compare AI models and create professional documentation!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7ce9471-1d2a-43ec-8a5e-9d885e3bcc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: reportlab in /opt/conda/lib/python3.12/site-packages (4.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /opt/conda/lib/python3.12/site-packages (from reportlab) (11.1.0)\n",
      "‚úÖ All packages installed and imported!\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Install and Import Everything\n",
    "# Install required packages\n",
    "!pip install requests reportlab\n",
    "\n",
    "# Import all required libraries\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import html\n",
    "import textwrap\n",
    "from datetime import datetime\n",
    "from typing import List, Dict\n",
    "\n",
    "# ReportLab imports for PDF generation\n",
    "from reportlab.lib.pagesizes import letter, A4\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.units import inch\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, PageBreak\n",
    "from reportlab.lib import colors\n",
    "from reportlab.lib.enums import TA_LEFT, TA_CENTER, TA_JUSTIFY\n",
    "\n",
    "print(\"‚úÖ All packages installed and imported!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c236ed6e-c5f3-407e-a233-44069ccfd7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ AIModelComparison class ready!\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Complete AI Comparison Class\n",
    "class AIModelComparison:\n",
    "    def __init__(self, api_key):\n",
    "        \"\"\"Initialize with your OpenRouter API key\"\"\"\n",
    "        self.api_key = api_key\n",
    "        self.base_url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "        self.headers = {\n",
    "            \"Authorization\": f\"Bearer {api_key}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        \n",
    "        # Popular models that work well\n",
    "        self.models = [\n",
    "            \"anthropic/claude-3.5-sonnet\",\n",
    "            \"meta-llama/llama-3.1-70b-instruct\",\n",
    "            \"openai/gpt-4o-mini\",\n",
    "            \"meta-llama/llama-2-70b-chat\",\n",
    "            \"google/gemini-flash-1.5\",\n",
    "            \"deepseek/deepseek-r1:free\"\n",
    "        ]\n",
    "        \n",
    "    def query_model(self, model: str, prompt: str, max_tokens: int = 1500) -> Dict:\n",
    "        \"\"\"Query a specific model\"\"\"\n",
    "        payload = {\n",
    "            \"model\": model,\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"temperature\": 0.7\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(self.base_url, headers=self.headers, json=payload, timeout=30)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                return {\n",
    "                    \"model\": model,\n",
    "                    \"success\": True,\n",
    "                    \"response\": data[\"choices\"][0][\"message\"][\"content\"].strip(),\n",
    "                    \"tokens_used\": data.get(\"usage\", {}).get(\"total_tokens\", \"N/A\"),\n",
    "                    \"error\": None\n",
    "                }\n",
    "            else:\n",
    "                return {\n",
    "                    \"model\": model,\n",
    "                    \"success\": False,\n",
    "                    \"response\": f\"Error: {response.status_code}\",\n",
    "                    \"tokens_used\": \"N/A\",\n",
    "                    \"error\": response.text\n",
    "                }\n",
    "                \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"model\": model,\n",
    "                \"success\": False,\n",
    "                \"response\": f\"Exception: {str(e)}\",\n",
    "                \"tokens_used\": \"N/A\",\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "    \n",
    "    def query_multiple_models(self, prompt: str, max_tokens: int = 1500, delay: float = 0.5) -> List[Dict]:\n",
    "        \"\"\"Query multiple models with the same prompt\"\"\"\n",
    "        responses = []\n",
    "        \n",
    "        print(f\"ü§ñ Querying {len(self.models)} models...\")\n",
    "        print(f\"üìù Prompt: {prompt[:100]}...\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        for i, model in enumerate(self.models, 1):\n",
    "            print(f\"[{i}/{len(self.models)}] Querying {model}...\", end=\" \")\n",
    "            \n",
    "            response = self.query_model(model, prompt, max_tokens)\n",
    "            responses.append(response)\n",
    "            \n",
    "            if response[\"success\"]:\n",
    "                print(\"‚úÖ\")\n",
    "            else:\n",
    "                print(\"‚ùå\")\n",
    "            \n",
    "            # Add delay to avoid rate limiting\n",
    "            if i < len(self.models):\n",
    "                time.sleep(delay)\n",
    "        \n",
    "        return responses\n",
    "    \n",
    "    def display_responses(self, responses: List[Dict], prompt: str):\n",
    "        \"\"\"Display responses in a nice readable format\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 120)\n",
    "        print(f\"üïí RESULTS - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        print(\"=\" * 120)\n",
    "        print(f\"üìù ORIGINAL PROMPT: {prompt}\")\n",
    "        print(\"=\" * 120)\n",
    "        \n",
    "        # Calculate column width\n",
    "        col_width = max(35, max(len(r[\"model\"]) for r in responses) + 5)\n",
    "        \n",
    "        # Header\n",
    "        header = f\"{'MODEL':<{col_width}} | {'STATUS':<8} | {'TOKENS':<8} | RESPONSE\"\n",
    "        print(header)\n",
    "        print(\"-\" * len(header))\n",
    "        \n",
    "        for response in responses:\n",
    "            model_name = response[\"model\"]\n",
    "            status = \"‚úÖ OK\" if response[\"success\"] else \"‚ùå FAIL\"\n",
    "            tokens = str(response[\"tokens_used\"])\n",
    "            resp_text = response[\"response\"]\n",
    "            \n",
    "            # Truncate long responses for table view\n",
    "            if len(resp_text) > 80:\n",
    "                resp_preview = resp_text[:77] + \"...\"\n",
    "            else:\n",
    "                resp_preview = resp_text\n",
    "            \n",
    "            # Replace newlines with spaces for table format\n",
    "            resp_preview = resp_preview.replace('\\n', ' ').replace('\\r', ' ')\n",
    "            \n",
    "            print(f\"{model_name:<{col_width}} | {status:<8} | {tokens:<8} | {resp_preview}\")\n",
    "        \n",
    "        print(\"=\" * 120)\n",
    "        \n",
    "        # Detailed responses\n",
    "        print(\"\\nüìã DETAILED RESPONSES:\")\n",
    "        print(\"=\" * 120)\n",
    "        \n",
    "        for i, response in enumerate(responses, 1):\n",
    "            print(f\"\\n[{i}] ü§ñ MODEL: {response['model']}\")\n",
    "            print(f\"üìä STATUS: {'‚úÖ Success' if response['success'] else '‚ùå Failed'}\")\n",
    "            print(f\"üî¢ TOKENS: {response['tokens_used']}\")\n",
    "            print(\"üìÑ RESPONSE:\")\n",
    "            print(\"-\" * 60)\n",
    "            print(response[\"response\"])\n",
    "            print(\"-\" * 60)\n",
    "\n",
    "print(\"‚úÖ AIModelComparison class ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8ad9de1-0491-4eb2-8dad-66d99f7dd75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed 2-Column PDF Generator Ready!\n",
      "Improvements:\n",
      "  - Robust character cleaning (no emojis)\n",
      "  - Better error handling and debugging\n",
      "  - Text length limits to prevent overflow\n",
      "  - Safer HTML formatting\n",
      "  - ASCII-only character set\n",
      "  - Improved table sizing for A4 pages\n",
      "‚úÖ Enhanced 2-Column PDF Generator Ready!\n",
      "üéØ Features:\n",
      "  üìã Clean 2-column table format\n",
      "  üìÑ Model Name | Full Response (no truncation)\n",
      "  ‚ú® Professional styling with alternating row colors\n",
      "  üî¢ Token counts and status indicators\n",
      "  üìä Summary statistics at top\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: PDF Generation Methods\n",
    "# Enhanced PDF Generation - Full 2-Column Layout\n",
    "\n",
    "def save_to_pdf_columns(self, responses: List[Dict], prompt: str, filename: str = None):\n",
    "    \"\"\"Save responses to PDF with 2-column layout - FIXED VERSION\"\"\"\n",
    "    if filename is None:\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        filename = f\"openrouter_responses_{timestamp}.pdf\"\n",
    "    \n",
    "    def clean_text_for_pdf(text: str) -> str:\n",
    "        \"\"\"Robust text cleaning for PDF generation\"\"\"\n",
    "        if not text:\n",
    "            return \"No content available\"\n",
    "        \n",
    "        # Convert to string\n",
    "        text = str(text)\n",
    "        \n",
    "        # Remove null bytes and other problematic control characters\n",
    "        text = text.replace('\\x00', '').replace('\\x08', '').replace('\\x0b', '').replace('\\x0c', '')\n",
    "        text = text.replace('\\x0e', '').replace('\\x0f', '').replace('\\x10', '').replace('\\x11', '')\n",
    "        \n",
    "        # Replace problematic characters with safe alternatives\n",
    "        replacements = {\n",
    "            '&': 'and',\n",
    "            '<': '[',\n",
    "            '>': ']',\n",
    "            '\"': \"'\",\n",
    "            '\\\\': '/',\n",
    "            '\\u2018': \"'\",  # Left single quote\n",
    "            '\\u2019': \"'\",  # Right single quote\n",
    "            '\\u201c': '\"',  # Left double quote\n",
    "            '\\u201d': '\"',  # Right double quote\n",
    "            '\\u2013': '-',  # En dash\n",
    "            '\\u2014': '-',  # Em dash\n",
    "            '\\u2026': '...',  # Ellipsis\n",
    "        }\n",
    "        \n",
    "        for old, new in replacements.items():\n",
    "            text = text.replace(old, new)\n",
    "        \n",
    "        # Replace newlines with space for table cells (ReportLab handles line breaks differently)\n",
    "        text = text.replace('\\n', ' ').replace('\\r', ' ')\n",
    "        \n",
    "        # Remove non-printable characters but keep basic punctuation\n",
    "        text = ''.join(char for char in text if ord(char) >= 32 and ord(char) <= 126)\n",
    "        \n",
    "        # Limit length to prevent table overflow\n",
    "        if len(text) > 3000:\n",
    "            text = text[:3000] + \"... [truncated for PDF]\"\n",
    "        \n",
    "        return text.strip() or \"No content\"\n",
    "    \n",
    "    try:\n",
    "        print(f\"Creating PDF: {filename}\")\n",
    "        \n",
    "        # Create PDF document\n",
    "        doc = SimpleDocTemplate(\n",
    "            filename,\n",
    "            pagesize=A4,\n",
    "            rightMargin=40,\n",
    "            leftMargin=40,\n",
    "            topMargin=50,\n",
    "            bottomMargin=50\n",
    "        )\n",
    "        \n",
    "        story = []\n",
    "        styles = getSampleStyleSheet()\n",
    "        \n",
    "        # Custom styles - safer approach\n",
    "        title_style = ParagraphStyle(\n",
    "            'SafeTitle',\n",
    "            parent=styles['Title'],\n",
    "            fontSize=18,\n",
    "            spaceAfter=20,\n",
    "            alignment=TA_CENTER,\n",
    "            textColor=colors.navy\n",
    "        )\n",
    "        \n",
    "        heading_style = ParagraphStyle(\n",
    "            'SafeHeading',\n",
    "            parent=styles['Heading2'],\n",
    "            fontSize=12,\n",
    "            spaceAfter=10,\n",
    "            spaceBefore=15,\n",
    "            textColor=colors.navy\n",
    "        )\n",
    "        \n",
    "        model_style = ParagraphStyle(\n",
    "            'SafeModel',\n",
    "            parent=styles['Normal'],\n",
    "            fontSize=9,\n",
    "            textColor=colors.navy,\n",
    "            alignment=TA_LEFT,\n",
    "            fontName='Helvetica-Bold'\n",
    "        )\n",
    "        \n",
    "        response_style = ParagraphStyle(\n",
    "            'SafeResponse',\n",
    "            parent=styles['Normal'],\n",
    "            fontSize=8,\n",
    "            alignment=TA_LEFT,\n",
    "            leftIndent=3,\n",
    "            rightIndent=3,\n",
    "            spaceAfter=2\n",
    "        )\n",
    "        \n",
    "        # Title\n",
    "        story.append(Paragraph(\"Multi-Model AI Comparison Report\", title_style))\n",
    "        story.append(Spacer(1, 12))\n",
    "        \n",
    "        # Metadata\n",
    "        story.append(Paragraph(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\", styles['Normal']))\n",
    "        story.append(Paragraph(f\"Total Models: {len(responses)}\", styles['Normal']))\n",
    "        \n",
    "        successful = sum(1 for r in responses if r[\"success\"])\n",
    "        story.append(Paragraph(f\"Successful Responses: {successful}/{len(responses)}\", styles['Normal']))\n",
    "        story.append(Spacer(1, 15))\n",
    "        \n",
    "        # Original prompt\n",
    "        story.append(Paragraph(\"Original Prompt\", heading_style))\n",
    "        clean_prompt = clean_text_for_pdf(prompt)\n",
    "        story.append(Paragraph(clean_prompt, styles['Normal']))\n",
    "        story.append(Spacer(1, 20))\n",
    "        \n",
    "        # Responses section\n",
    "        story.append(Paragraph(\"Model Responses\", heading_style))\n",
    "        \n",
    "        # Prepare table data with safer formatting\n",
    "        table_data = []\n",
    "        \n",
    "        # Header row\n",
    "        table_data.append([\n",
    "            Paragraph(\"Model Name\", model_style),\n",
    "            Paragraph(\"Response\", model_style)\n",
    "        ])\n",
    "        \n",
    "        # Data rows\n",
    "        for response in responses:\n",
    "            # Model name with status (using text symbols instead of emojis)\n",
    "            model_name = response[\"model\"].split('/')[-1]\n",
    "            status_symbol = \"[OK]\" if response[\"success\"] else \"[FAIL]\"\n",
    "            tokens = f\"({response['tokens_used']} tokens)\" if response[\"success\"] and response[\"tokens_used\"] != \"N/A\" else \"\"\n",
    "            \n",
    "            # Safe model cell content\n",
    "            model_cell_text = f\"{model_name} {status_symbol} {tokens}\"\n",
    "            model_cell_clean = clean_text_for_pdf(model_cell_text)\n",
    "            \n",
    "            # Response content\n",
    "            if response[\"success\"]:\n",
    "                response_text = clean_text_for_pdf(response[\"response\"])\n",
    "            else:\n",
    "                error_text = response.get(\"error\", response[\"response\"])\n",
    "                response_text = f\"Error: {clean_text_for_pdf(error_text)}\"\n",
    "            \n",
    "            # Add to table\n",
    "            table_data.append([\n",
    "                Paragraph(model_cell_clean, model_style),\n",
    "                Paragraph(response_text, response_style)\n",
    "            ])\n",
    "        \n",
    "        # Create table with proper column widths\n",
    "        col_widths = [2.2*inch, 4.8*inch]  # Adjusted for A4\n",
    "        \n",
    "        comparison_table = Table(table_data, colWidths=col_widths, repeatRows=1)\n",
    "        \n",
    "        # Simplified table styling\n",
    "        table_style = [\n",
    "            # Header\n",
    "            ('BACKGROUND', (0, 0), (-1, 0), colors.navy),\n",
    "            ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),\n",
    "            ('ALIGN', (0, 0), (-1, 0), 'CENTER'),\n",
    "            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "            ('FONTSIZE', (0, 0), (-1, 0), 10),\n",
    "            ('BOTTOMPADDING', (0, 0), (-1, 0), 8),\n",
    "            ('TOPPADDING', (0, 0), (-1, 0), 8),\n",
    "            \n",
    "            # Data cells\n",
    "            ('BACKGROUND', (0, 1), (-1, -1), colors.white),\n",
    "            ('TEXTCOLOR', (0, 1), (-1, -1), colors.black),\n",
    "            ('ALIGN', (0, 1), (-1, -1), 'LEFT'),\n",
    "            ('VALIGN', (0, 1), (-1, -1), 'TOP'),\n",
    "            ('FONTNAME', (0, 1), (-1, -1), 'Helvetica'),\n",
    "            ('FONTSIZE', (0, 1), (-1, -1), 8),\n",
    "            ('LEFTPADDING', (0, 1), (-1, -1), 6),\n",
    "            ('RIGHTPADDING', (0, 1), (-1, -1), 6),\n",
    "            ('TOPPADDING', (0, 1), (-1, -1), 8),\n",
    "            ('BOTTOMPADDING', (0, 1), (-1, -1), 8),\n",
    "            \n",
    "            # Borders\n",
    "            ('GRID', (0, 0), (-1, -1), 0.5, colors.grey),\n",
    "            ('LINEBELOW', (0, 0), (-1, 0), 2, colors.navy),\n",
    "        ]\n",
    "        \n",
    "        # Add alternating row colors\n",
    "        for i in range(1, len(table_data)):\n",
    "            if i % 2 == 0:\n",
    "                table_style.append(('BACKGROUND', (0, i), (-1, i), colors.lightgrey))\n",
    "        \n",
    "        comparison_table.setStyle(TableStyle(table_style))\n",
    "        \n",
    "        # Add table to story\n",
    "        story.append(comparison_table)\n",
    "        story.append(Spacer(1, 20))\n",
    "        \n",
    "        # Footer\n",
    "        footer_text = f\"Report generated on {datetime.now().strftime('%Y-%m-%d at %H:%M:%S')}\"\n",
    "        story.append(Paragraph(footer_text, styles['Normal']))\n",
    "        \n",
    "        # Build the PDF\n",
    "        doc.build(story)\n",
    "        print(f\"PDF successfully created: {filename}\")\n",
    "        print(\"Features:\")\n",
    "        print(\"  - 2-column layout (Model | Response)\")\n",
    "        print(\"  - Full responses included\")\n",
    "        print(\"  - Professional table formatting\")\n",
    "        print(\"  - Status indicators and token counts\")\n",
    "        print(\"  - Robust character handling\")\n",
    "        return filename\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating PDF: {str(e)}\")\n",
    "        print(f\"Error type: {type(e).__name__}\")\n",
    "        \n",
    "        # Try to provide more specific error information\n",
    "        import traceback\n",
    "        print(\"Detailed error:\")\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        return None\n",
    "\n",
    "# Replace the PDF method with the fixed version\n",
    "AIModelComparison.save_to_pdf = save_to_pdf_columns\n",
    "\n",
    "print(\"Fixed 2-Column PDF Generator Ready!\")\n",
    "print(\"Improvements:\")\n",
    "print(\"  - Robust character cleaning (no emojis)\")\n",
    "print(\"  - Better error handling and debugging\")\n",
    "print(\"  - Text length limits to prevent overflow\") \n",
    "print(\"  - Safer HTML formatting\")\n",
    "print(\"  - ASCII-only character set\")\n",
    "print(\"  - Improved table sizing for A4 pages\")\n",
    "\n",
    "\n",
    "def save_to_pdf_columns(self, responses: List[Dict], prompt: str, filename: str = None):\n",
    "    \"\"\"Save responses to PDF with 2-column layout: Model Name | Full Response\"\"\"\n",
    "    if filename is None:\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        filename = f\"openrouter_responses_{timestamp}.pdf\"\n",
    "    \n",
    "    def clean_text_for_pdf(text: str) -> str:\n",
    "        \"\"\"Clean text for PDF while preserving formatting\"\"\"\n",
    "        if not text:\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to string and basic cleanup\n",
    "        text = str(text).replace('\\x00', '').replace('\\x08', '').replace('\\x0b', '').replace('\\x0c', '')\n",
    "        \n",
    "        # Handle common problematic characters for ReportLab\n",
    "        text = text.replace('&', '&amp;')\n",
    "        text = text.replace('<', '&lt;')\n",
    "        text = text.replace('>', '&gt;')\n",
    "        \n",
    "        # Preserve line breaks and formatting\n",
    "        text = text.replace('\\n', '<br/>')\n",
    "        \n",
    "        # Remove only truly problematic characters\n",
    "        text = ''.join(char for char in text if ord(char) >= 32 or char in '\\n\\r\\t')\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    try:\n",
    "        # Create PDF with wider margins for better table layout\n",
    "        doc = SimpleDocTemplate(\n",
    "            filename,\n",
    "            pagesize=A4,\n",
    "            rightMargin=36,  # Smaller margins for more space\n",
    "            leftMargin=36,\n",
    "            topMargin=50,\n",
    "            bottomMargin=50\n",
    "        )\n",
    "        \n",
    "        story = []\n",
    "        styles = getSampleStyleSheet()\n",
    "        \n",
    "        # Custom styles\n",
    "        title_style = ParagraphStyle(\n",
    "            'CustomTitle',\n",
    "            parent=styles['Title'],\n",
    "            fontSize=20,\n",
    "            spaceAfter=20,\n",
    "            alignment=TA_CENTER,\n",
    "            textColor=colors.darkblue\n",
    "        )\n",
    "        \n",
    "        heading_style = ParagraphStyle(\n",
    "            'CustomHeading',\n",
    "            parent=styles['Heading2'],\n",
    "            fontSize=14,\n",
    "            spaceAfter=10,\n",
    "            spaceBefore=15,\n",
    "            textColor=colors.darkblue\n",
    "        )\n",
    "        \n",
    "        # Style for model names in table\n",
    "        model_style = ParagraphStyle(\n",
    "            'ModelStyle',\n",
    "            parent=styles['Normal'],\n",
    "            fontSize=10,\n",
    "            textColor=colors.darkblue,\n",
    "            alignment=TA_LEFT,\n",
    "            fontName='Helvetica-Bold'\n",
    "        )\n",
    "        \n",
    "        # Style for responses in table\n",
    "        response_style = ParagraphStyle(\n",
    "            'ResponseStyle',\n",
    "            parent=styles['Normal'],\n",
    "            fontSize=9,\n",
    "            alignment=TA_JUSTIFY,\n",
    "            leftIndent=5,\n",
    "            rightIndent=5,\n",
    "            spaceAfter=3\n",
    "        )\n",
    "        \n",
    "        # Title and header info\n",
    "        story.append(Paragraph(\"Multi-Model LLM Comparison Report\", title_style))\n",
    "        story.append(Spacer(1, 10))\n",
    "        \n",
    "        # Metadata\n",
    "        story.append(Paragraph(f\"<b>Generated:</b> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\", styles['Normal']))\n",
    "        story.append(Paragraph(f\"<b>Total Models:</b> {len(responses)}\", styles['Normal']))\n",
    "        \n",
    "        successful = sum(1 for r in responses if r[\"success\"])\n",
    "        story.append(Paragraph(f\"<b>Successful Responses:</b> {successful}/{len(responses)}\", styles['Normal']))\n",
    "        story.append(Spacer(1, 15))\n",
    "        \n",
    "        # Original prompt\n",
    "        story.append(Paragraph(\"Original Prompt\", heading_style))\n",
    "        clean_prompt = clean_text_for_pdf(prompt)\n",
    "        story.append(Paragraph(clean_prompt, response_style))\n",
    "        story.append(Spacer(1, 20))\n",
    "        \n",
    "        # Create the main comparison table\n",
    "        story.append(Paragraph(\"Model Responses Comparison\", heading_style))\n",
    "        \n",
    "        # Prepare table data\n",
    "        table_data = []\n",
    "        \n",
    "        # Header row\n",
    "        table_data.append([\n",
    "            Paragraph('<b>Model Name</b>', model_style),\n",
    "            Paragraph('<b>Response</b>', model_style)\n",
    "        ])\n",
    "        \n",
    "        # Data rows - each model and its full response\n",
    "        for response in responses:\n",
    "            # Model name with status\n",
    "            model_name = response[\"model\"].split('/')[-1]  # Get just the model name\n",
    "            status_icon = \"‚úÖ\" if response[\"success\"] else \"‚ùå\"\n",
    "            tokens = f\"({response['tokens_used']} tokens)\" if response[\"success\"] else \"\"\n",
    "            \n",
    "            model_cell = f\"<b>{model_name}</b><br/>{status_icon} {tokens}\"\n",
    "            \n",
    "            # Full response (no truncation)\n",
    "            if response[\"success\"]:\n",
    "                full_response = clean_text_for_pdf(response[\"response\"])\n",
    "            else:\n",
    "                full_response = f\"<i>Error:</i> {clean_text_for_pdf(response['response'])}\"\n",
    "            \n",
    "            # Add row to table\n",
    "            table_data.append([\n",
    "                Paragraph(model_cell, model_style),\n",
    "                Paragraph(full_response, response_style)\n",
    "            ])\n",
    "        \n",
    "        # Create table with appropriate column widths\n",
    "        # Model name column: 2.5 inches, Response column: 5 inches\n",
    "        col_widths = [2.5*inch, 5*inch]\n",
    "        \n",
    "        comparison_table = Table(table_data, colWidths=col_widths, repeatRows=1)\n",
    "        \n",
    "        # Style the table\n",
    "        table_style = [\n",
    "            # Header row styling\n",
    "            ('BACKGROUND', (0, 0), (-1, 0), colors.darkblue),\n",
    "            ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),\n",
    "            ('ALIGN', (0, 0), (-1, 0), 'CENTER'),\n",
    "            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "            ('FONTSIZE', (0, 0), (-1, 0), 11),\n",
    "            ('BOTTOMPADDING', (0, 0), (-1, 0), 10),\n",
    "            ('TOPPADDING', (0, 0), (-1, 0), 10),\n",
    "            \n",
    "            # Data rows styling\n",
    "            ('BACKGROUND', (0, 1), (-1, -1), colors.white),\n",
    "            ('TEXTCOLOR', (0, 1), (-1, -1), colors.black),\n",
    "            ('ALIGN', (0, 1), (-1, -1), 'LEFT'),\n",
    "            ('VALIGN', (0, 1), (-1, -1), 'TOP'),  # Align to top\n",
    "            ('FONTNAME', (0, 1), (-1, -1), 'Helvetica'),\n",
    "            ('FONTSIZE', (0, 1), (-1, -1), 9),\n",
    "            ('LEFTPADDING', (0, 1), (-1, -1), 8),\n",
    "            ('RIGHTPADDING', (0, 1), (-1, -1), 8),\n",
    "            ('TOPPADDING', (0, 1), (-1, -1), 10),\n",
    "            ('BOTTOMPADDING', (0, 1), (-1, -1), 10),\n",
    "            \n",
    "            # Grid and borders\n",
    "            ('GRID', (0, 0), (-1, -1), 1, colors.grey),\n",
    "            ('LINEBELOW', (0, 0), (-1, 0), 2, colors.darkblue),\n",
    "            \n",
    "            # Alternating row colors for better readability\n",
    "        ]\n",
    "        \n",
    "        # Add alternating row colors\n",
    "        for i in range(1, len(table_data)):\n",
    "            if i % 2 == 0:\n",
    "                table_style.append(('BACKGROUND', (0, i), (-1, i), colors.lightgrey))\n",
    "        \n",
    "        comparison_table.setStyle(TableStyle(table_style))\n",
    "        \n",
    "        # Add table to story\n",
    "        story.append(comparison_table)\n",
    "        story.append(Spacer(1, 20))\n",
    "        \n",
    "        # Footer\n",
    "        story.append(Paragraph(\n",
    "            f\"<i>Report generated by OpenRouter Multi-Model Comparison Tool on {datetime.now().strftime('%Y-%m-%d at %H:%M:%S')}</i>\",\n",
    "            styles['Normal']\n",
    "        ))\n",
    "        \n",
    "        # Build the PDF\n",
    "        doc.build(story)\n",
    "        print(f\"üìÑ Enhanced 2-column PDF saved: {filename}\")\n",
    "        print(\"‚úÖ Features:\")\n",
    "        print(\"  ‚Ä¢ Clean 2-column layout (Model | Response)\")\n",
    "        print(\"  ‚Ä¢ Full responses with NO text cutoff\")\n",
    "        print(\"  ‚Ä¢ Professional table formatting\")\n",
    "        print(\"  ‚Ä¢ Status indicators and token counts\")\n",
    "        return filename\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error creating enhanced PDF: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Replace the PDF method\n",
    "AIModelComparison.save_to_pdf = save_to_pdf_columns\n",
    "\n",
    "print(\"‚úÖ Enhanced 2-Column PDF Generator Ready!\")\n",
    "print(\"üéØ Features:\")\n",
    "print(\"  üìã Clean 2-column table format\")\n",
    "print(\"  üìÑ Model Name | Full Response (no truncation)\")\n",
    "print(\"  ‚ú® Professional styling with alternating row colors\")\n",
    "print(\"  üî¢ Token counts and status indicators\")\n",
    "print(\"  üìä Summary statistics at top\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2932326-5269-4c04-a842-cd9938d89ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ JSON export method added!\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: JSON Export Method\n",
    "def save_to_json(self, responses: List[Dict], prompt: str, filename: str = None):\n",
    "    \"\"\"Save responses to a JSON file\"\"\"\n",
    "    if filename is None:\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        filename = f\"openrouter_responses_{timestamp}.json\"\n",
    "    \n",
    "    data = {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"prompt\": prompt,\n",
    "        \"responses\": responses,\n",
    "        \"statistics\": {\n",
    "            \"total_models\": len(responses),\n",
    "            \"successful_responses\": sum(1 for r in responses if r[\"success\"]),\n",
    "            \"failed_responses\": sum(1 for r in responses if not r[\"success\"]),\n",
    "            \"total_tokens\": sum(int(r[\"tokens_used\"]) for r in responses if str(r[\"tokens_used\"]).isdigit())\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"üíæ JSON saved: {filename}\")\n",
    "    return filename\n",
    "\n",
    "# Add to class\n",
    "AIModelComparison.save_to_json = save_to_json\n",
    "\n",
    "print(\"‚úÖ JSON export method added!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "358a977c-e583-4e17-884c-3352b6a682ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your OpenRouter API key:  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\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîë API key configured!\n",
      "üöÄ AI assistant ready with 6 models!\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Setup API Key\n",
    "# Get your free API key from: https://openrouter.ai/\n",
    "api_key = os.getenv('OPENROUTER_API_KEY')\n",
    "\n",
    "if not api_key:\n",
    "    api_key = input(\"Enter your OpenRouter API key: \").strip()\n",
    "\n",
    "if api_key:\n",
    "    print(\"üîë API key configured!\")\n",
    "    ai = AIModelComparison(api_key)\n",
    "    print(f\"üöÄ AI assistant ready with {len(ai.models)} models!\")\n",
    "else:\n",
    "    print(\"‚ùå Need API key to continue. Get one from: https://openrouter.ai/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28dc2520-8c2d-4413-a9c8-d215112838e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéâ Enhanced interactive mode ready!\n",
      "üí° Call: interactive_comparison_enhanced()\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Interactive Mode\n",
    "def interactive_comparison_enhanced():\n",
    "    \"\"\"Interactive mode with enhanced 2-column PDF\"\"\"\n",
    "    if 'ai' not in globals():\n",
    "        print(\"‚ùå AI assistant not found\")\n",
    "        return\n",
    "    \n",
    "    print(\"üéÆ Enhanced Interactive AI Model Comparison\")\n",
    "    print(\"üìã New Feature: 2-Column PDF (Model | Full Response)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    user_prompt = input(\"Enter your question: \").strip()\n",
    "    \n",
    "    if not user_prompt:\n",
    "        print(\"‚ùå Empty prompt!\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        max_tokens = int(input(\"Max tokens (default 800): \") or 800)\n",
    "    except ValueError:\n",
    "        max_tokens = 800\n",
    "    \n",
    "    # Query all models\n",
    "    print(\"\\nü§ñ Querying all models...\")\n",
    "    results = ai.query_multiple_models(user_prompt, max_tokens)\n",
    "    \n",
    "    # Display results\n",
    "    ai.display_responses(results, user_prompt)\n",
    "    \n",
    "    # Ask about saving\n",
    "    save_files = input(\"\\nüíæ Generate enhanced 2-column PDF report? (y/n): \").lower().strip()\n",
    "    \n",
    "    if save_files == 'y':\n",
    "        pdf_file = ai.save_to_pdf(results, user_prompt)\n",
    "        json_file = ai.save_to_json(results, user_prompt)\n",
    "        print(f\"\\n‚úÖ Reports saved:\")\n",
    "        print(f\"  üìÑ PDF (2-column): {pdf_file}\")\n",
    "        print(f\"  üíæ JSON: {json_file}\")\n",
    "    \n",
    "    print(\"‚ú® Enhanced comparison completed!\")\n",
    "\n",
    "print(\"üéâ Enhanced interactive mode ready!\")\n",
    "print(\"üí° Call: interactive_comparison_enhanced()\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7097fa8-4c60-4208-a27c-1f88287bad2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéÆ Enhanced Interactive AI Model Comparison\n",
      "üìã New Feature: 2-Column PDF (Model | Full Response)\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your question:  beschreibe Rechtfertigungslehre aus lutherischer und katholischer sicht\n",
      "Max tokens (default 800):  100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Querying all models...\n",
      "ü§ñ Querying 6 models...\n",
      "üìù Prompt: beschreibe Rechtfertigungslehre aus lutherischer und katholischer sicht...\n",
      "================================================================================\n",
      "[1/6] Querying anthropic/claude-3.5-sonnet... ‚úÖ\n",
      "[2/6] Querying meta-llama/llama-3.1-70b-instruct... ‚úÖ\n",
      "[3/6] Querying openai/gpt-4o-mini... ‚úÖ\n",
      "[4/6] Querying meta-llama/llama-2-70b-chat... ‚ùå\n",
      "[5/6] Querying google/gemini-flash-1.5... ‚úÖ\n",
      "[6/6] Querying deepseek/deepseek-r1:free... ‚úÖ\n",
      "\n",
      "========================================================================================================================\n",
      "üïí RESULTS - 2025-07-22 12:41:55\n",
      "========================================================================================================================\n",
      "üìù ORIGINAL PROMPT: beschreibe Rechtfertigungslehre aus lutherischer und katholischer sicht\n",
      "========================================================================================================================\n",
      "MODEL                                  | STATUS   | TOKENS   | RESPONSE\n",
      "-----------------------------------------------------------------------\n",
      "anthropic/claude-3.5-sonnet            | ‚úÖ OK     | 126      | Die Rechtfertigungslehre ist ein zentrales theologisches Konzept, das die Fra...\n",
      "meta-llama/llama-3.1-70b-instruct      | ‚úÖ OK     | 133      | Die Rechtfertigungslehre ist ein zentrales Thema in der christlichen Theologi...\n",
      "openai/gpt-4o-mini                     | ‚úÖ OK     | 0        | Die Rechtfertigungslehre ist ein zentrales Thema in der Theologie und weist w...\n",
      "meta-llama/llama-2-70b-chat            | ‚ùå FAIL   | N/A      | Error: 404\n",
      "google/gemini-flash-1.5                | ‚úÖ OK     | 114      | Die Rechtfertigungslehre ist ein zentraler Streitpunkt zwischen Lutheranern u...\n",
      "deepseek/deepseek-r1:free              | ‚úÖ OK     | 127      | \n",
      "========================================================================================================================\n",
      "\n",
      "üìã DETAILED RESPONSES:\n",
      "========================================================================================================================\n",
      "\n",
      "[1] ü§ñ MODEL: anthropic/claude-3.5-sonnet\n",
      "üìä STATUS: ‚úÖ Success\n",
      "üî¢ TOKENS: 126\n",
      "üìÑ RESPONSE:\n",
      "------------------------------------------------------------\n",
      "Die Rechtfertigungslehre ist ein zentrales theologisches Konzept, das die Frage behandelt, wie der Mensch vor Gott gerecht wird. Hier die wichtigsten Unterschiede zwischen lutherischer und katholischer Sicht:\n",
      "\n",
      "Lutherische Rechtfertigungslehre:\n",
      "\n",
      "1. Sola Gratia (Allein durch Gnade):\n",
      "- Rechtfertigung erfol\n",
      "------------------------------------------------------------\n",
      "\n",
      "[2] ü§ñ MODEL: meta-llama/llama-3.1-70b-instruct\n",
      "üìä STATUS: ‚úÖ Success\n",
      "üî¢ TOKENS: 133\n",
      "üìÑ RESPONSE:\n",
      "------------------------------------------------------------\n",
      "Die Rechtfertigungslehre ist ein zentrales Thema in der christlichen Theologie, das sich mit der Frage besch√§ftigt, wie der Mensch vor Gott gerecht wird. Die Lehre von der Rechtfertigung ist ein wichtiger Unterschied zwischen der lutherischen und der katholischen Theologie.\n",
      "\n",
      "**Lutherische Sicht:**\n",
      "\n",
      "In der lutherischen Theologie wird die Rechtfertigung als ein Geschenk G\n",
      "------------------------------------------------------------\n",
      "\n",
      "[3] ü§ñ MODEL: openai/gpt-4o-mini\n",
      "üìä STATUS: ‚úÖ Success\n",
      "üî¢ TOKENS: 0\n",
      "üìÑ RESPONSE:\n",
      "------------------------------------------------------------\n",
      "Die Rechtfertigungslehre ist ein zentrales Thema in der Theologie und weist wesentliche Unterschiede zwischen der lutherischen und der katholischen Sicht auf.\n",
      "\n",
      "### Lutherische Sicht\n",
      "\n",
      "1. **Gnade allein**: Die lutherische Theologie betont, dass die Rechtfertigung allein durch den Glauben an Jesus Christus und durch die Gnade Gottes erfolgt. Menschen sind durch ihre Taten nicht in der Lage, sich selbst zu rechtfertigen.\n",
      "\n",
      "2. **Imputation**\n",
      "------------------------------------------------------------\n",
      "\n",
      "[4] ü§ñ MODEL: meta-llama/llama-2-70b-chat\n",
      "üìä STATUS: ‚ùå Failed\n",
      "üî¢ TOKENS: N/A\n",
      "üìÑ RESPONSE:\n",
      "------------------------------------------------------------\n",
      "Error: 404\n",
      "------------------------------------------------------------\n",
      "\n",
      "[5] ü§ñ MODEL: google/gemini-flash-1.5\n",
      "üìä STATUS: ‚úÖ Success\n",
      "üî¢ TOKENS: 114\n",
      "üìÑ RESPONSE:\n",
      "------------------------------------------------------------\n",
      "Die Rechtfertigungslehre ist ein zentraler Streitpunkt zwischen Lutheranern und Katholiken, der sich auf die Frage konzentriert, wie der Mensch vor Gott gerechtfertigt, also als gerecht angesehen wird.  Beide Konfessionen glauben an die Notwendigkeit der Gnade Gottes zur Rechtfertigung, aber sie unterscheiden sich erheblich in ihrer Auffassung, wie diese Gnade wirkt und was dazu beitr√§gt.\n",
      "\n",
      "**Lutherische Sicht:**\n",
      "\n",
      "Die lutherische Rechtfertigungslehre, stark gepr√§gt von Martin Luthers\n",
      "------------------------------------------------------------\n",
      "\n",
      "[6] ü§ñ MODEL: deepseek/deepseek-r1:free\n",
      "üìä STATUS: ‚úÖ Success\n",
      "üî¢ TOKENS: 127\n",
      "üìÑ RESPONSE:\n",
      "------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Generate enhanced 2-column PDF report? (y/n):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Enhanced 2-column PDF saved: openrouter_responses_20250722_124200.pdf\n",
      "‚úÖ Features:\n",
      "  ‚Ä¢ Clean 2-column layout (Model | Response)\n",
      "  ‚Ä¢ Full responses with NO text cutoff\n",
      "  ‚Ä¢ Professional table formatting\n",
      "  ‚Ä¢ Status indicators and token counts\n",
      "üíæ JSON saved: openrouter_responses_20250722_124200.json\n",
      "\n",
      "‚úÖ Reports saved:\n",
      "  üìÑ PDF (2-column): openrouter_responses_20250722_124200.pdf\n",
      "  üíæ JSON: openrouter_responses_20250722_124200.json\n",
      "‚ú® Enhanced comparison completed!\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Execute interactive Mode\n",
    "interactive_comparison_enhanced()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69c15b5-4265-4055-819c-bf530dc570bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
