{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Please note that the majority of this codebase (approximately 90%) was AI-generated by the large language model `anthropic/claude-sonnet-4`.\n",
    "The author's contributions included the initial design, code review, integration, and comprehensive testing.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Introduction (Markdown)\n",
    "### LLM-based OCR Processing and Text Extraction Pipeline\n",
    "\n",
    "**This notebook demonstrates a complete workflow to:**\n",
    "- OCR historical PDFs with different LLM with OCR capacity API via OpenRouter API,\n",
    "- Output the extracted text in both `.txt` and `.pdf` form while preserving formatting,\n",
    "- Generate a new PDF with original and OCR text side-by-side,\n",
    "- Automatically process all PDFs in a folder.\n",
    "\n",
    "**Key steps covered:**\n",
    "- API call setup and usage for OCR extraction,\n",
    "- Reading and writing PDF content,\n",
    "- Assembling results and exporting.\n",
    "\n",
    "**Required packages:**  \n",
    "- `requests`, `PyMuPDF` (`fitz`), `PyPDF2`, `tqdm`\n",
    "\n",
    "**‚ö†Ô∏è Before you start:**  \n",
    "- Update all file paths to match your local environment.\n",
    "- Insert your OpenRouter API key.\n",
    "\n",
    "**üí∞ Cost Consideration:**\n",
    "- The Mistral OCR API accessed via OpenRouter typically costs around $2.00 per 1000 pages processed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Imports and Global Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import base64\n",
    "import json\n",
    "import requests\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import glob\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "import cv2\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "# Try to import Tesseract OCR as fallback\n",
    "try:\n",
    "    import pytesseract\n",
    "    TESSERACT_AVAILABLE = True\n",
    "    # You might need to set the tesseract path on some systems\n",
    "    # pytesseract.pytesseract.tesseract_cmd = r'/usr/local/bin/tesseract'  # macOS with brew\n",
    "    # pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'  # Windows\n",
    "except ImportError:\n",
    "    TESSERACT_AVAILABLE = False\n",
    "    print(\"Tesseract not available. Install with: pip install pytesseract\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Before run this cell, define your input, outputh path and create API key for OpenRouter\n",
    "#### - Visit: [https://openrouter.ai/docs/api-reference/api-keys/create-api-key](https://openrouter.ai/docs/api-reference/api-keys/create-api-key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and output paths\n",
    "\n",
    "INPUT_FOLDER = \"/Users/[YOUR USER NAME]/Downloads/abc/\"  # ‚ö†Ô∏è Replace with your actual input folder\n",
    "OUTPUT_PDF_PATH = \"/Users/[YOUR USER NAME]/Downloads/abc/ocr-output.pdf\"  # Base name - will be modified based on selected model\n",
    "\n",
    "# API key will be set by get_api_key() function\n",
    "OPENROUTER_API_KEY = None\n",
    "OCR_INSTRUCTION = \"\"\"\n",
<<<<<<< HEAD
    "Extract all text from this historical document.\n",
    "Correct likely OCR errors while preserving historical language.\n",
    "Consider paper aging, faded ink, old typography, and handwritten annotations.\n",
    "Preserve the original text layout as much as possible maintaining paragraph structure and formatting\n",
    "Include all visible text on each page.\n",
    "DO NOT add content that isn't visible in the original\n",
    "Mark uncertain text with [?] if unsure\n",
    "\n",
=======
    "Extract all text from this document image.\n",
    "This appears to be a scanned document that may have curved or distorted text.\n",
    "Focus on accurately reading any visible text, numbers, dates, or other content.\n",
    "Ignore any visual distortions and focus on the actual text content.\n",
    "Preserve the original text layout as much as possible.\n",
    "Include all visible text on the page.\n",
    "DO NOT add content that isn't visible in the original.\n",
    "Mark uncertain text with [?] if unsure.\n",
    "If the text appears to be repeating numbers or nonsensical, describe what you actually see in the image instead.\n",
>>>>>>> b6cded7 (new version)
    "\"\"\"\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def get_api_key():\n",
    "    \"\"\"\n",
    "    Get OpenRouter API key from environment variable or user input\n",
    "    \"\"\"\n",
    "    global OPENROUTER_API_KEY\n",
    "    \n",
    "    # First, try to get from environment variable\n",
    "    openrouter_api_key = os.getenv('OPENROUTER_API_KEY')\n",
    "    \n",
    "    if not openrouter_api_key:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"üîë API KEY REQUIRED\")\n",
    "        print(\"=\"*70)\n",
    "        print(\"OpenRouter API key not found in environment variables.\")\n",
    "        print(\"You can set it as an environment variable: OPENROUTER_API_KEY\")\n",
    "        print(\"Or enter it manually below.\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                openrouter_api_key = input(\"Enter your OpenRouter API key: \").strip()\n",
    "                \n",
    "                if not openrouter_api_key:\n",
    "                    print(\"‚ùå API key cannot be empty. Please try again.\")\n",
    "                    continue\n",
    "                \n",
    "                if not openrouter_api_key.startswith('sk-or-v1-'):\n",
    "                    print(\"‚ö†Ô∏è  Warning: OpenRouter API keys typically start with 'sk-or-v1-'\")\n",
    "                    confirm = input(\"Continue anyway? (y/n): \").strip().lower()\n",
    "                    if confirm not in ['y', 'yes']:\n",
    "                        continue\n",
    "                \n",
    "                print(\"‚úÖ API key accepted!\")\n",
    "                break\n",
    "                \n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\n\\n‚ùå Operation cancelled by user.\")\n",
    "                return None\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error: {e}\")\n",
    "                continue\n",
    "    else:\n",
    "        print(\"‚úÖ OpenRouter API key found in environment variables.\")\n",
    "    \n",
    "    OPENROUTER_API_KEY = openrouter_api_key\n",
    "    return openrouter_api_key\n",
    "\n",
    "def tesseract_ocr_fallback(image_path):\n",
    "    \"\"\"\n",
    "    Fallback OCR using Tesseract if available\n",
    "    \"\"\"\n",
    "    if not TESSERACT_AVAILABLE:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Open and preprocess image for Tesseract\n",
    "        img = Image.open(image_path)\n",
    "        \n",
    "        # Convert to grayscale\n",
    "        if img.mode != 'L':\n",
    "            img = img.convert('L')\n",
    "        \n",
    "        # Enhance contrast\n",
    "        enhancer = ImageEnhance.Contrast(img)\n",
    "        img = enhancer.enhance(2.0)\n",
    "        \n",
    "        # Extract text using Tesseract\n",
    "        custom_config = r'--oem 3 --psm 6'  # OCR Engine Mode 3, Page Segmentation Mode 6\n",
    "        text = pytesseract.image_to_string(img, config=custom_config)\n",
    "        \n",
    "        if text.strip():\n",
    "            logger.info(f\"Tesseract extracted {len(text)} characters\")\n",
    "            return f\"[TESSERACT OCR RESULT]\\n\\n{text}\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Tesseract OCR failed: {e}\")\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Utility: PDF ‚Üí base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_image_for_ocr(image_path, output_path):\n",
    "    \"\"\"\n",
    "    Enhanced image preprocessing with multiple techniques\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read image with OpenCV\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            pil_img = Image.open(image_path)\n",
    "            img = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Try multiple preprocessing approaches\n",
    "        processed_images = []\n",
    "        \n",
    "        # Approach 1: CLAHE enhancement\n",
    "        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "        enhanced1 = clahe.apply(gray)\n",
    "        processed_images.append((\"clahe\", enhanced1))\n",
    "        \n",
    "        # Approach 2: Gaussian blur + threshold\n",
    "        blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "        _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        processed_images.append((\"threshold\", thresh))\n",
    "        \n",
    "        # Approach 3: Adaptive threshold\n",
    "        adaptive = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "        processed_images.append((\"adaptive\", adaptive))\n",
    "        \n",
    "        # Use the CLAHE version as it often works best for varied lighting\n",
    "        final_img = enhanced1\n",
    "        \n",
    "        # Convert back to PIL and save\n",
    "        pil_enhanced = Image.fromarray(final_img)\n",
    "        if pil_enhanced.mode != 'RGB':\n",
    "            pil_enhanced = pil_enhanced.convert('RGB')\n",
    "        \n",
    "        pil_enhanced.save(output_path, 'JPEG', quality=95)\n",
    "        logger.info(f\"Enhanced image saved to {output_path}\")\n",
    "        return output_path\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Image enhancement failed, using original: {e}\")\n",
    "        Image.open(image_path).save(output_path)\n",
    "        return output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: OCR Extraction with Mistral OCR via the OpenRouter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output_filename(base_path, selected_model):\n",
    "    \"\"\"\n",
    "    Generate output filename based on selected model\n",
    "    \"\"\"\n",
    "    base_path = Path(base_path)\n",
    "    \n",
    "    # Clean the model name for use in filename\n",
    "    if selected_model == \"auto\":\n",
    "        model_suffix = \"auto-multi-model\"\n",
    "    else:\n",
    "        # Replace slashes and other problematic characters\n",
    "        model_suffix = selected_model.replace(\"/\", \"-\").replace(\":\", \"-\").replace(\" \", \"-\")\n",
    "    \n",
    "    # Create new filename with model suffix\n",
    "    new_filename = f\"{base_path.stem}-{model_suffix}{base_path.suffix}\"\n",
    "    new_path = base_path.parent / new_filename\n",
    "    \n",
    "    return str(new_path)\n",
    "\n",
    "def get_user_model_choice():\n",
    "    \"\"\"\n",
    "    Ask user to choose which OCR model to use\n",
    "    \"\"\"\n",
    "    available_models = {\n",
    "        \"1\": {\n",
    "            \"model\": \"mistral-ocr\",\n",
    "            \"description\": \"Mistral's specialized OCR engine - Good for PDFs with complex layouts\"\n",
    "        },\n",
    "        \"2\": {\n",
    "            \"model\": \"openai/gpt-4o\",\n",
    "            \"description\": \"Excellent for complex documents, handwriting, and high accuracy OCR\"\n",
    "        },\n",
    "        \"3\": {\n",
    "            \"model\": \"anthropic/claude-3-5-sonnet\",\n",
    "            \"description\": \"Superior document understanding and high accuracy\"\n",
    "        },\n",
    "        \"4\": {\n",
    "            \"model\": \"openai/gpt-4o-mini\",\n",
    "            \"description\": \"Good balance of cost and performance\"\n",
    "        },\n",
    "        \"5\": {\n",
    "            \"model\": \"auto\",\n",
    "            \"description\": \"Try multiple models automatically (fallback approach)\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üìä CHOOSE OCR MODEL\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for key, value in available_models.items():\n",
    "        print(f\"{key}. {value['model']}\")\n",
    "        print(f\"   ‚Üí {value['description']}\")\n",
    "        print()\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            choice = input(\"Enter your choice (1-8): \").strip()\n",
    "            \n",
    "            if choice in available_models:\n",
    "                selected = available_models[choice]\n",
    "                print(f\"\\n‚úÖ Selected: {selected['model']}\")\n",
    "                print(f\"   {selected['description']}\")\n",
    "                return selected['model']\n",
    "            else:\n",
    "                print(\"‚ùå Invalid choice. Please enter a number between 1-5.\")\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n\\n‚ùå Operation cancelled by user.\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "def encode_file_to_base64(file_path):\n",
    "    \"\"\"\n",
    "    Encode file (PDF or image) to base64 string (for API upload).\n",
    "    \"\"\"\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        return base64.b64encode(file.read()).decode('utf-8')\n",
    "\n",
    "def get_file_mime_type(file_path):\n",
    "    \"\"\"\n",
    "    Get the MIME type for the file based on its extension.\n",
    "    \"\"\"\n",
    "    file_ext = Path(file_path).suffix.lower()\n",
    "    mime_types = {\n",
    "        '.pdf': 'application/pdf',\n",
    "        '.jpg': 'image/jpeg',\n",
    "        '.jpeg': 'image/jpeg',\n",
    "        '.png': 'image/png',\n",
    "        '.tiff': 'image/tiff',\n",
    "        '.tif': 'image/tiff',\n",
    "        '.bmp': 'image/bmp'\n",
    "    }\n",
    "    return mime_types.get(file_ext, 'application/octet-stream')\n",
    "\n",
    "def jpg_to_pdf(jpg_path, output_pdf_path):\n",
    "    \"\"\"\n",
    "    Convert JPG image to PDF for consistent processing.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = Image.open(jpg_path)\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "        img.save(output_pdf_path, \"PDF\", resolution=100.0)\n",
    "        logger.info(f\"Converted {jpg_path} to PDF: {output_pdf_path}\")\n",
    "        return output_pdf_path\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error converting JPG to PDF: {e}\")\n",
    "        return None\n",
    "\n",
    "def is_repetitive_output(text):\n",
    "    \"\"\"\n",
    "    Detect if the OCR output is repetitive/nonsensical\n",
    "    \"\"\"\n",
    "    if len(text) < 100:\n",
    "        return False\n",
    "    \n",
    "    lines = [line.strip() for line in text.split('\\n') if line.strip()]\n",
    "    \n",
    "    # Check for excessive markdown headers\n",
    "    markdown_headers = [line for line in lines if line.startswith('##')]\n",
    "    if len(markdown_headers) > 50:\n",
    "        return True\n",
    "    \n",
    "    # Check for repeating patterns\n",
    "    if len(lines) > 20:\n",
    "        unique_lines = set(lines)\n",
    "        if len(unique_lines) < len(lines) * 0.1:  # Less than 10% unique content\n",
    "            return True\n",
    "    \n",
    "    # Check for year sequences (like 2000, 2001, 2002...)\n",
    "    year_pattern_count = len([line for line in lines if line.strip() in [str(year) for year in range(1900, 2100)]])\n",
    "    if year_pattern_count > 20:\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def ocr_with_multiple_methods(file_path, enhanced_image_path=None, selected_model=None):\n",
    "    \"\"\"\n",
    "    Try OCR with selected model or multiple methods in sequence\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # If user selected auto, use multiple models approach\n",
    "    if selected_model == \"auto\" or selected_model is None:\n",
    "        models_to_try = [\n",
    "            \"mistral-ocr\",                      # Mistral's specialized OCR engine\n",
    "            \"openai/gpt-4o\",                    # Excellent for complex documents, handwriting\n",
    "            \"anthropic/claude-3-5-sonnet\",     # Superior document understanding\n",
    "            \"openai/gpt-4o-mini\",              # Good balance of cost/performance\n",
    "        ]\n",
    "        \n",
    "        print(f\"üîÑ Trying multiple models automatically...\")\n",
    "        \n",
    "        for model in models_to_try:\n",
    "            try:\n",
    "                result = ocr_with_openrouter(file_path, model)\n",
    "                if result and not is_repetitive_output(result):\n",
    "                    logger.info(f\"Success with model: {model}\")\n",
    "                    return result\n",
    "                elif result:\n",
    "                    results.append(f\"[MODEL: {model} - REPETITIVE OUTPUT]\\n{result[:500]}...\")\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Model {model} failed: {e}\")\n",
    "                continue\n",
    "    else:\n",
    "        # Use the selected model\n",
    "        print(f\"üéØ Using selected model: {selected_model}\")\n",
    "        try:\n",
    "            result = ocr_with_openrouter(file_path, selected_model)\n",
    "            if result and not is_repetitive_output(result):\n",
    "                logger.info(f\"Success with selected model: {selected_model}\")\n",
    "                return result\n",
    "            elif result:\n",
    "                results.append(f\"[MODEL: {selected_model} - REPETITIVE OUTPUT]\\n{result[:500]}...\")\n",
    "                print(f\"‚ö†Ô∏è  Selected model gave repetitive output, trying fallback methods...\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Selected model {selected_model} failed: {e}\")\n",
    "            print(f\"‚ùå Selected model failed, trying fallback methods...\")\n",
    "    \n",
    "    # Fallback: Try Tesseract on enhanced image\n",
    "    if enhanced_image_path and TESSERACT_AVAILABLE:\n",
    "        print(\"üîÑ Trying Tesseract OCR as fallback...\")\n",
    "        tesseract_result = tesseract_ocr_fallback(enhanced_image_path)\n",
    "        if tesseract_result and len(tesseract_result.strip()) > 10:\n",
    "            logger.info(\"Success with Tesseract OCR\")\n",
    "            return tesseract_result\n",
    "    \n",
    "    # If all methods failed, return a summary\n",
    "    if results:\n",
    "        return f\"[MULTIPLE OCR ATTEMPTS FAILED - POSSIBLE IMAGE QUALITY ISSUES]\\n\\nAttempted results:\\n\\n\" + \"\\n\\n\".join(results)\n",
    "    else:\n",
    "        return \"[OCR_FAILED] Unable to extract meaningful text from this image. The image may contain curved text, be too low quality, or have other issues preventing accurate OCR.\"\n",
    "\n",
    "def ocr_with_openrouter(file_path, model=\"google/gemma-3-27b-it\"):\n",
    "    \"\"\"\n",
    "    Use OpenRouter API to extract text from a file\n",
    "    \"\"\"\n",
    "    if not OPENROUTER_API_KEY:\n",
    "        raise ValueError(\"API key is missing.\")\n",
    "        \n",
    "    url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"HTTP-Referer\": \"https://localhost\",\n",
    "        \"X-Title\": \"Document OCR Application\"\n",
    "    }\n",
    "    \n",
    "    base64_file = encode_file_to_base64(file_path)\n",
    "    mime_type = get_file_mime_type(file_path)\n",
    "    data_url = f\"data:{mime_type};base64,{base64_file}\"\n",
    "    \n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": OCR_INSTRUCTION\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"file\",\n",
    "                    \"file\": {\n",
    "                        \"filename\": Path(file_path).name,\n",
    "                        \"file_data\": data_url\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": model if model != \"mistral-ocr\" else \"google/gemma-3-27b-it\",\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": 2000 if model != \"mistral-ocr\" else 4000,\n",
    "        \"temperature\": 0.1\n",
    "    }\n",
    "    \n",
    "    # Add Mistral OCR plugin if specified\n",
    "    if model == \"mistral-ocr\":\n",
    "        payload[\"plugins\"] = [\n",
    "            {\n",
    "                \"id\": \"file-parser\",\n",
    "                \"pdf\": {\n",
    "                    \"engine\": \"mistral-ocr\"\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    \n",
    "    try:\n",
    "        logger.info(f\"Trying OCR with model: {model}\")\n",
    "        response = requests.post(url, headers=headers, json=payload)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        \n",
    "        if \"choices\" in result and len(result[\"choices\"]) > 0:\n",
    "            extracted_text = result[\"choices\"][0][\"message\"][\"content\"]\n",
    "            logger.info(f\"Extracted {len(extracted_text)} characters with {model}\")\n",
    "            return extracted_text\n",
    "        else:\n",
    "            logger.error(f\"Unexpected API response from {model}: {result}\")\n",
    "            return \"\"\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logger.error(f\"API request failed for {model}: {e}\")\n",
    "        if hasattr(e, 'response') and e.response is not None:\n",
    "            logger.error(f\"Response: {e.response.text}\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Utility: Convert Extracted Text to a Paginated PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_pdf(text_content, output_path, original_filename=\"\", page_offset=0):\n",
    "    \"\"\"\n",
    "    Create a PDF file from text content.\n",
    "    \"\"\"\n",
    "    doc = fitz.open()\n",
    "    font_size = 10\n",
    "    font_name = \"Courier\"\n",
    "    header_font_size = 8\n",
    "    \n",
    "    # Split the text into \"pages\" by line count\n",
    "    text_pages = []\n",
    "    lines = text_content.split('\\n')\n",
    "    current_page = []\n",
    "    line_count = 0\n",
    "    max_lines_per_page = 55\n",
    "    \n",
    "    for line in lines:\n",
    "        current_page.append(line)\n",
    "        line_count += 1\n",
    "        if (line_count >= max_lines_per_page and line.strip() == '') or line_count >= max_lines_per_page + 10:\n",
    "            text_pages.append('\\n'.join(current_page))\n",
    "            current_page = []\n",
    "            line_count = 0\n",
    "    if current_page:\n",
    "        text_pages.append('\\n'.join(current_page))\n",
    "\n",
    "    page_width = 595\n",
    "    page_height = 842\n",
    "    \n",
    "    for page_num, page_text in enumerate(text_pages):\n",
    "        page = doc.new_page(width=page_width, height=page_height)\n",
    "        left_margin = 50\n",
    "        right_margin = 50\n",
    "        top_margin = 70\n",
    "        bottom_margin = 50\n",
    "        \n",
    "        if original_filename:\n",
    "            header_text = f\"{original_filename} - Page {page_offset + page_num + 1}\"\n",
    "            header_rect = fitz.Rect(left_margin, 20, page_width - right_margin, 50)\n",
    "            page.insert_textbox(\n",
    "                header_rect,\n",
    "                header_text,\n",
    "                fontsize=header_font_size,\n",
    "                fontname=\"helvetica-bold\",\n",
    "                align=1,\n",
    "                color=(0.5, 0.5, 0.5)\n",
    "            )\n",
    "            line_y = 55\n",
    "            page.draw_line(\n",
    "                fitz.Point(left_margin, line_y),\n",
    "                fitz.Point(page_width - right_margin, line_y),\n",
    "                color=(0.7, 0.7, 0.7),\n",
    "                width=0.5\n",
    "            )\n",
    "        \n",
    "        text_rect = fitz.Rect(\n",
    "            left_margin,\n",
    "            top_margin,\n",
    "            page_width - right_margin,\n",
    "            page_height - bottom_margin\n",
    "        )\n",
    "        page.insert_textbox(\n",
    "            text_rect,\n",
    "            page_text,\n",
    "            fontsize=font_size,\n",
    "            fontname=font_name,\n",
    "            align=0\n",
    "        )\n",
    "    doc.save(output_path)\n",
    "    doc.close()\n",
    "    return output_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: Utility: Merge Original PDF and Text PDF Side-by-Side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_pdfs_side_by_side(original_pdf_path, text_pdf_path, output_path, original_filename=\"\"):\n",
    "    \"\"\"\n",
    "    Merge original PDF and OCR text PDF side by side, page by page.\n",
    "    \"\"\"\n",
    "    original_doc = fitz.open(original_pdf_path)\n",
    "    text_doc = fitz.open(text_pdf_path)\n",
    "    result_doc = fitz.open()\n",
    "    \n",
    "    max_pages = max(original_doc.page_count, text_doc.page_count)\n",
    "    original_width = original_doc[0].rect.width if original_doc.page_count > 0 else 595\n",
    "    original_height = original_doc[0].rect.height if original_doc.page_count > 0 else 842\n",
    "    \n",
    "    for page_num in range(max_pages):\n",
    "        result_page = result_doc.new_page(\n",
    "            width=original_width * 2,\n",
    "            height=original_height\n",
    "        )\n",
    "        if page_num < original_doc.page_count:\n",
    "            result_page.show_pdf_page(\n",
    "                fitz.Rect(0, 0, original_width, original_height),\n",
    "                original_doc,\n",
    "                page_num\n",
    "            )\n",
    "        if page_num < text_doc.page_count:\n",
    "            result_page.show_pdf_page(\n",
    "                fitz.Rect(original_width, 0, original_width * 2, original_height),\n",
    "                text_doc,\n",
    "                page_num\n",
    "            )\n",
    "        else:\n",
    "            if original_filename:\n",
    "                header_text = f\"{original_filename} - Page {page_num + 1}\"\n",
    "                header_rect = fitz.Rect(original_width + 50, 20, original_width * 2 - 50, 50)\n",
    "                result_page.insert_textbox(\n",
    "                    header_rect,\n",
    "                    header_text,\n",
    "                    fontsize=8,\n",
    "                    fontname=\"helvetica-bold\",\n",
    "                    align=1,\n",
    "                    color=(0.5, 0.5, 0.5)\n",
    "                )\n",
    "    result_doc.save(output_path)\n",
    "    result_doc.close()\n",
    "    original_doc.close()\n",
    "    text_doc.close()\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: Process a Single PDF File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file_path, output_pdf_path, page_offset=0, selected_model=None):\n",
    "    \"\"\"\n",
    "    Process a single file with selected OCR model\n",
    "    \"\"\"\n",
    "    logger.info(f\"Processing file: {file_path}\")\n",
    "    original_filename = Path(file_path).stem\n",
    "    file_ext = Path(file_path).suffix.lower()\n",
    "    \n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        temp_dir_path = Path(temp_dir)\n",
    "        enhanced_image_path = None\n",
    "        \n",
    "        if file_ext in ['.jpg', '.jpeg', '.png', '.tiff', '.tif', '.bmp']:\n",
    "            # Enhance image\n",
    "            enhanced_image_path = temp_dir_path / f\"enhanced{file_ext}\"\n",
    "            enhance_image_for_ocr(file_path, enhanced_image_path)\n",
    "            \n",
    "            # Convert to PDF\n",
    "            temp_pdf_path = temp_dir_path / \"converted.pdf\"\n",
    "            converted_pdf = jpg_to_pdf(enhanced_image_path, temp_pdf_path)\n",
    "            if not converted_pdf:\n",
    "                logger.error(f\"Failed to convert {file_path} to PDF\")\n",
    "                return None, None\n",
    "            processing_file = converted_pdf\n",
    "            ocr_file = converted_pdf\n",
    "        else:\n",
    "            processing_file = file_path\n",
    "            ocr_file = file_path\n",
    "        \n",
    "        # Try OCR with selected model\n",
    "        extracted_text = ocr_with_multiple_methods(ocr_file, enhanced_image_path, selected_model)\n",
    "        \n",
    "        # Save extracted text\n",
    "        text_file_path = temp_dir_path / \"extracted_text.txt\"\n",
    "        with open(text_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(extracted_text)\n",
    "        \n",
    "        # Create text PDF\n",
    "        text_pdf_path = temp_dir_path / \"text.pdf\"\n",
    "        create_text_pdf(extracted_text, text_pdf_path, original_filename, page_offset)\n",
    "        \n",
    "        # Merge PDFs\n",
    "        merge_pdfs_side_by_side(processing_file, text_pdf_path, output_pdf_path, original_filename)\n",
    "        \n",
    "        # Save text output\n",
    "        text_output_path = Path(output_pdf_path).with_suffix('.txt')\n",
    "        with open(text_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(extracted_text)\n",
    "    \n",
    "    logger.info(f\"Completed processing {file_path}\")\n",
    "    return output_pdf_path, text_output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 9: Batch Process All PDFs in a Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_supported_files(input_folder):\n",
    "    \"\"\"\n",
    "    Get all supported files (PDF and image files) from the input folder.\n",
    "    \"\"\"\n",
    "    supported_extensions = ['*.pdf', '*.jpg', '*.jpeg', '*.png', '*.tiff', '*.tif', '*.bmp']\n",
    "    all_files = []\n",
    "    \n",
    "    for extension in supported_extensions:\n",
    "        files = glob.glob(os.path.join(input_folder, extension))\n",
    "        files.extend(glob.glob(os.path.join(input_folder, extension.upper())))\n",
    "        all_files.extend(files)\n",
    "    \n",
    "    return sorted(list(set(all_files)))\n",
    "\n",
    "def process_folder(input_folder, output_pdf_path, selected_model=None):\n",
    "    \"\"\"\n",
    "    Process all supported files in a folder with selected OCR model\n",
    "    \"\"\"\n",
    "    files = get_supported_files(input_folder)\n",
    "    if not files:\n",
    "        logger.error(f\"No supported files found in {input_folder}\")\n",
    "        return None, None\n",
    "    \n",
    "    logger.info(f\"Found {len(files)} files to process: {[Path(f).name for f in files]}\")\n",
    "    combined_text = \"\"\n",
    "    \n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        temp_dir_path = Path(temp_dir)\n",
    "        processed_pdfs = []\n",
    "        total_pages = 0\n",
    "        \n",
    "        for index, file_path in enumerate(tqdm(files, desc=\"Processing files\")):\n",
    "            output_file = temp_dir_path / f\"processed_{index}.pdf\"\n",
    "            try:\n",
    "                # Pass the selected_model to process_file\n",
    "                result = process_file(file_path, output_file, total_pages, selected_model)\n",
    "                if result[0]:\n",
    "                    _, text_file = result\n",
    "                    processed_pdfs.append(output_file)\n",
    "                    \n",
    "                    file_ext = Path(file_path).suffix.lower()\n",
    "                    if file_ext in ['.jpg', '.jpeg', '.png', '.tiff', '.tif', '.bmp']:\n",
    "                        total_pages += 1\n",
    "                    else:\n",
    "                        doc = fitz.open(file_path)\n",
    "                        total_pages += doc.page_count\n",
    "                        doc.close()\n",
    "                    \n",
    "                    file_name = os.path.basename(file_path)\n",
    "                    combined_text += f\"\\n\\n=== {file_name} ===\\n\\n\"\n",
    "                    if Path(text_file).exists():\n",
    "                        combined_text += Path(text_file).read_text(encoding=\"utf-8\")\n",
    "                        combined_text += \"\\n\\n\"\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing {file_path}: {e}\", exc_info=True)\n",
    "        \n",
    "        if processed_pdfs:\n",
    "            combined_doc = fitz.open()\n",
    "            for pdf_path in processed_pdfs:\n",
    "                doc = fitz.open(pdf_path)\n",
    "                combined_doc.insert_pdf(doc)\n",
    "                doc.close()\n",
    "            combined_doc.save(output_pdf_path)\n",
    "            combined_doc.close()\n",
    "            \n",
    "            text_output_path = Path(output_pdf_path).with_suffix('.txt')\n",
    "            with open(text_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(combined_text)\n",
    "            \n",
    "            logger.info(f\"Combined PDF saved to {output_pdf_path}\")\n",
    "            logger.info(f\"Combined text saved to {text_output_path}\")\n",
    "            return output_pdf_path, text_output_path\n",
    "        else:\n",
    "            logger.error(\"No files were successfully processed\")\n",
    "            return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 10: Main Entrypoint Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Entrypoint for batch processing.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"üöÄ OCR Document Processing Tool\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Step 1: Get API key\n",
    "        api_key = get_api_key()\n",
    "        if not api_key:\n",
    "            print(\"‚ùå API key is required. Exiting...\")\n",
    "            return\n",
    "        \n",
    "        # Step 2: Get user's model choice\n",
    "        selected_model = get_user_model_choice()\n",
    "        if selected_model is None:\n",
    "            print(\"‚ùå No model selected. Exiting...\")\n",
    "            return\n",
    "        \n",
    "        # Step 3: Generate output filename based on selected model\n",
    "        output_pdf_path = generate_output_filename(OUTPUT_PDF_PATH, selected_model)\n",
    "        \n",
    "        print(f\"\\nüìã PROCESSING SUMMARY\")\n",
    "        print(f\"üìÅ Input folder: {INPUT_FOLDER}\")\n",
    "        print(f\"ü§ñ Selected model: {selected_model}\")\n",
    "        print(f\"üíæ Output will be saved to: {output_pdf_path}\")\n",
    "        \n",
    "        # Ask for confirmation\n",
    "        confirm = input(f\"\\nProceed with processing? (y/n): \").strip().lower()\n",
    "        if confirm not in ['y', 'yes']:\n",
    "            print(\"‚ùå Processing cancelled by user.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\nüöÄ Starting processing...\")\n",
    "        \n",
    "        results = process_folder(INPUT_FOLDER, output_pdf_path, selected_model)\n",
    "        if results:\n",
    "            print(f\"\\nüéâ SUCCESS!\")\n",
    "            print(f\"üìÑ PDF saved to: {results[0]}\")\n",
    "            print(f\"üìù Text saved to: {results[1]}\")\n",
    "        else:\n",
    "            print(\"‚ùå Processing completed with errors. Check the log for details.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing files: {e}\", exc_info=True)\n",
    "        print(f\"‚ùå Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 11: Run the Program\n",
    "### NOTE: Only run this after you've configured the paths and API key!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
